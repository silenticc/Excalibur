{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd7nLO8F8pwD"
      },
      "outputs": [],
      "source": [
        "# make sure you have the latest version of sigmoid_check installed with !pip install sigmoid_check --upgrade\n",
        "from sigmoid_check.excalibur import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pda7JS5w8pwD",
        "outputId": "62f5b0aa-cbac-4da8-86fb-4a1719388f20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Given a list of dictionaries `data`, create a pandas DataFrame named `df_from_dict`.\n",
        "@check_pandas_1\n",
        "def pandas_1(data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_from_dict = pd.DataFrame(data)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_from_dict\": df_from_dict}\n",
        "\n",
        "pandas_1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I9yY5Dr8pwE",
        "outputId": "e5cdee5a-f2db-4889-ea25-5da28283a5ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a pandas Series named `series_from_list` from a list of floats `float_list`, with no index specified.\n",
        "@check_pandas_2\n",
        "def pandas_2(float_list):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    series_from_list = pd.Series(float_list)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"series_from_list\": series_from_list}\n",
        "\n",
        "pandas_2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTZ5ZjN38pwE",
        "outputId": "86911fa3-8e44-4a3f-b40b-b4087818637e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Given a dictionary `dict_data` containing country names as keys and populations as values, create a pandas Series named `country_population`, using the dictionary keys as index.\n",
        "@check_pandas_3\n",
        "def pandas_3(dict_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    country_population = pd.Series(dict_data, index=dict_data.keys())\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"country_population\": country_population}\n",
        "\n",
        "pandas_3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsh7lwtD8pwE",
        "outputId": "2bea2300-c6f2-47a9-ea3d-fbbb4ddbe251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# From a pandas Series `series_population`, access the index and save it in a variable `population_index`.\n",
        "@check_pandas_4\n",
        "def pandas_4(series_population):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    population_index = series_population.index\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"population_index\": population_index}\n",
        "\n",
        "pandas_4()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgK7mS958pwE",
        "outputId": "0d75fc5c-cdd7-46e6-ec0a-da190f27ce08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Using a pandas Series `series_temperatures`, extract the values and store them in a variable `temperature_values`.\n",
        "@check_pandas_5\n",
        "def pandas_5(series_temperatures):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    temperature_values = series_temperatures.values\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"temperature_values\": temperature_values}\n",
        "\n",
        "pandas_5()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeywFqxK8pwF",
        "outputId": "e9b095f4-80f4-45c6-bb5b-3c281587f3de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# For a pandas Series `series_ages`, get the data type of the elements in the series and store it in a variable `ages_dtype`.\n",
        "@check_pandas_6\n",
        "def pandas_6(series_ages):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    ages_dtype = series_ages.dtype\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"ages_dtype\": ages_dtype}\n",
        "\n",
        "pandas_6()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPaHD4n18pwF",
        "outputId": "76771544-867e-4d3b-82f9-834fb394c8e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# From a Series `series_custom_index` with a custom index, access the element with index 'A' and store it in a variable `element_A`.\n",
        "@check_pandas_7\n",
        "def pandas_7(series_custom_index):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    element_A = series_custom_index[\"A\"]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"element_A\": element_A}\n",
        "\n",
        "pandas_7()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xc5Kne-P8pwF",
        "outputId": "b127d030-10d6-401d-bb10-b5a514e479f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Using a pandas Series `series_items`, slice the series to contain elements with indices from 'b' to 'd', inclusive, and save it into `sliced_series`.\n",
        "@check_pandas_8\n",
        "def pandas_8(series_items):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    sliced_series = series_items[\"b\":\"d\"]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sliced_series\": sliced_series}\n",
        "\n",
        "pandas_8()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzHAtXp88pwF",
        "outputId": "f7fe20fe-2117-4f6d-c289-7968cd7b900a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# From a Series `series_prices`, select elements with custom indices ['apple', 'banana', 'cherry'] and store them in `selected_prices`.\n",
        "@check_pandas_9\n",
        "def pandas_9(series_prices):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    selected_prices = series_prices.loc[[\"apple\", \"banana\", \"cherry\"]]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"selected_prices\": selected_prices}\n",
        "\n",
        "pandas_9()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVIhfvcW8pwF",
        "outputId": "c3728432-5881-47b4-aa26-350d887c8a42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a DataFrame `df_custom` from a list of lists `list_of_lists_data`, ensuring to label the columns as 'A', 'B', 'C'.\n",
        "@check_pandas_10\n",
        "def pandas_10(list_of_lists_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_custom = pd.DataFrame(list_of_lists_data, columns=['A', 'B', 'C'])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_custom\": df_custom}\n",
        "\n",
        "pandas_10()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0jkvW598pwF",
        "outputId": "20b2d077-3d64-467b-84fb-f04c69848d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Given a list of tuples `data_tuples`, create a DataFrame named `df_from_tuples` and rename its columns to 'X', 'Y', 'Z'.\n",
        "@check_pandas_11\n",
        "def pandas_11(data_tuples):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_from_tuples = pd.DataFrame(data_tuples,columns=['X','Y','Z'])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_from_tuples\": df_from_tuples}\n",
        "\n",
        "pandas_11()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NO2fo1m8pwG",
        "outputId": "923e8a1b-19c3-4d0b-90e1-bb70a02ec39b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Using DataFrame `df_sales`, access and store the column names in variable `sales_columns`.\n",
        "@check_pandas_12\n",
        "def pandas_12(df_sales):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    sales_columns = df_sales.columns\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sales_columns\": sales_columns}\n",
        "\n",
        "pandas_12()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgDZfsq-8pwG",
        "outputId": "8b94a437-718c-4c12-92a6-b32ee0925559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Store the index of the DataFrame `df_employees` in a variable `employees_index`.\n",
        "@check_pandas_13\n",
        "def pandas_13(df_employees):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    employees_index = df_employees.index\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"employees_index\": employees_index}\n",
        "\n",
        "pandas_13()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWzg5OP_8pwG",
        "outputId": "70ad719a-6f76-40bf-acfb-4f8e42f4e1f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the values from DataFrame `df_weather` and save them into `weather_values`.\n",
        "@check_pandas_14\n",
        "def pandas_14(df_weather):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    weather_values = df_weather.values\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"weather_values\": weather_values}\n",
        "\n",
        "pandas_14()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7l9birS8pwG",
        "outputId": "2fb4bf38-c42b-454b-86b8-7f02e70f4931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Determine the shape of the DataFrame `df_financials` and store it in a variable `financials_shape`.\n",
        "@check_pandas_15\n",
        "def pandas_15(df_financials):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    financials_shape = df_financials.shape\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"financials_shape\": financials_shape}\n",
        "\n",
        "pandas_15()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vw6ruzOO8pwG",
        "outputId": "4d4e9ef8-31c5-47fa-e125-0d4d7c9eda0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Get the data types of each column in DataFrame `df_customer_info` and store them in a variable `customer_info_dtypes`.\n",
        "@check_pandas_16\n",
        "def pandas_16(df_customer_info):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    customer_info_dtypes = df_customer_info.dtypes\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"customer_info_dtypes\": customer_info_dtypes}\n",
        "\n",
        "pandas_16()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IgUieSA8pwG",
        "outputId": "6c06fef2-bc2f-4548-b03d-bebe16cb45fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Using the DataFrame `df_transactions`, get the first 5 rows and store them in `transactions_head`.\n",
        "@check_pandas_17\n",
        "def pandas_17(df_transactions):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    transactions_head = df_transactions.head(5)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"transactions_head\": transactions_head}\n",
        "\n",
        "pandas_17()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNuVNXVf8pwG",
        "outputId": "40bcb035-b139-4d78-a515-da59abad3ccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the last 3 rows from DataFrame `df_activities` and save them into `activities_tail`.\n",
        "@check_pandas_18\n",
        "def pandas_18(df_activities):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    activities_tail = df_activities.tail(3)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"activities_tail\": activities_tail}\n",
        "\n",
        "pandas_18()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XG5vB7jS8pwG",
        "outputId": "270b6de8-f4e5-4e1d-ea41-b17e50a75e8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Product   3 non-null      object\n",
            " 1   Quantity  3 non-null      int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 180.0+ bytes\n",
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Get a summary of information about DataFrame `df_inventory`, storing the result in a variable `inventory_info`.\n",
        "@check_pandas_19\n",
        "def pandas_19(df_inventory):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    inventory_info = df_inventory.info()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"inventory_info\": inventory_info}\n",
        "\n",
        "pandas_19()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezFM6xgx8pwH",
        "outputId": "4eaa9b42-c78e-4f8b-8a59-7bc5446a75e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# For the DataFrame `df_scores`, generate descriptive statistics and store them in `scores_statistics`.\n",
        "@check_pandas_20\n",
        "def pandas_20(df_scores):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    scores_statistics = df_scores.describe()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"scores_statistics\": scores_statistics}\n",
        "\n",
        "pandas_20()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IebB2NQG8pwH",
        "outputId": "6f85a752-0735-45b0-9c40-e1ed221a16e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_orders` to create a boolean mask `orders_non_missing`, detecting non-missing values.\n",
        "@check_pandas_21\n",
        "def pandas_21(df_orders):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    orders_non_missing = df_orders.notna()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"orders_non_missing\": orders_non_missing}\n",
        "\n",
        "pandas_21()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rUUFSTD8pwH",
        "outputId": "337f3175-08ef-4400-ebf6-2ea09e6da688"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Drop rows with missing values in DataFrame `df_stats` and save the result into `cleaned_stats`.\n",
        "@check_pandas_22\n",
        "def pandas_22(df_stats):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    cleaned_stats = df_stats.dropna()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"cleaned_stats\": cleaned_stats}\n",
        "\n",
        "pandas_22()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXSr17rc8pwH",
        "outputId": "ce008f81-94df-4265-a65f-4a91cfb37a8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# From DataFrame `df_statistics`, drop columns with missing values and store the result into `statistics_cleaned`.\n",
        "@check_pandas_23\n",
        "def pandas_23(df_statistics):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    statistics_cleaned = df_statistics.dropna(axis=1)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"statistics_cleaned\": statistics_cleaned}\n",
        "\n",
        "pandas_23()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boQXzYR58pwH",
        "outputId": "1249faa7-1eca-4ff5-e63e-d8fb1f3f3408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Fill missing values in DataFrame `df_grades` with 0 and store the resultant DataFrame in `filled_grades`.\n",
        "@check_pandas_24\n",
        "def pandas_24(df_grades):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    filled_grades = df_grades.fillna(0)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"filled_grades\": filled_grades}\n",
        "\n",
        "pandas_24()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wXNKHOq8pwH",
        "outputId": "50367bf4-d6ae-4bad-c9c9-5a574e363eb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_7396\\1183282474.py:8: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  filled_bfill_sales_data = df_sales_data.fillna(method='bfill')\n"
          ]
        }
      ],
      "source": [
        "# Apply backward fill on DataFrame `df_sales_data` for missing values and save it into `filled_bfill_sales_data`.\n",
        "@check_pandas_25\n",
        "def pandas_25(df_sales_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    filled_bfill_sales_data = df_sales_data.fillna(method='bfill')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"filled_bfill_sales_data\": filled_bfill_sales_data}\n",
        "\n",
        "pandas_25()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk57tHPp8pwH",
        "outputId": "ff733778-9db8-459b-a2a0-ce217ba1a5aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_7396\\2446993458.py:8: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  filled_ffill_attendance = df_attendance.fillna(method='ffill')\n"
          ]
        }
      ],
      "source": [
        "# Apply forward fill on DataFrame `df_attendance` and store the results in `filled_ffill_attendance`.\n",
        "@check_pandas_26\n",
        "def pandas_26(df_attendance):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    filled_ffill_attendance = df_attendance.fillna(method='ffill')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"filled_ffill_attendance\": filled_ffill_attendance}\n",
        "\n",
        "pandas_26()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cT_M8IGb8pwH",
        "outputId": "602c8b3b-da8b-44be-a889-e31a55fd49fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set 'OrderID' as the index of DataFrame `df_orders_list` and save the updated DataFrame as `orders_indexed`.\n",
        "@check_pandas_27\n",
        "def pandas_27(df_orders_list):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    orders_indexed = df_orders_list.set_index('OrderID')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"orders_indexed\": orders_indexed}\n",
        "\n",
        "pandas_27()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASViTIGu8pwH",
        "outputId": "53af6dc7-3251-4b86-b189-d6286b359b0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Reset the index of a DataFrame `df_indexed_data` and store it in `df_reset_index`.\n",
        "@check_pandas_28\n",
        "def pandas_28(df_indexed_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_reset_index = df_indexed_data.reset_index()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_reset_index\": df_reset_index}\n",
        "\n",
        "pandas_28()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2WWfL8l8pwI",
        "outputId": "4c760005-5cf1-41b9-d299-b3327917c8f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a DataFrame `df_multiindex` with hierarchical indexing from `multiindex_data_list` using levels 'Region' and 'Category'.\n",
        "@check_pandas_29\n",
        "def pandas_29(multiindex_data_list):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_multiindex = pd.DataFrame(multiindex_data_list, columns=['Region', 'Category', 'Sales'])\n",
        "    df_multiindex.set_index(['Region', 'Category'], inplace=True)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_multiindex\": df_multiindex}\n",
        "\n",
        "pandas_29()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXerA-Qx8pwI",
        "outputId": "4c2996d2-6eeb-475f-a9b3-060e25d27154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_exams` to filter rows with Score > 80 using boolean indexing and save it in `high_score_exams`.\n",
        "@check_pandas_30\n",
        "def pandas_30(df_exams):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    high_score_exams = df_exams[df_exams['Score'] > 80]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"high_score_exams\": high_score_exams}\n",
        "\n",
        "pandas_30()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPJTUvKY8pwI",
        "outputId": "8d82d73d-af10-4999-e88b-c2cea6d18aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# From DataFrame `df_transactions`, select the row with label 'TX005' and store it in `transaction_TX005`.\n",
        "@check_pandas_31\n",
        "def pandas_31(df_transactions):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    transaction_TX005 = df_transactions.loc['TX005']\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"transaction_TX005\": transaction_TX005}\n",
        "\n",
        "pandas_31()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tY6HCBl8pwI",
        "outputId": "2d3371d2-bf8b-472a-bd82-87b9e4828b1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_sports` to select rows labeled ['Basketball', 'Football'] and columns labeled ['Wins', 'Losses'], storing the result in `selected_sports`.\n",
        "@check_pandas_32\n",
        "def pandas_32(df_sports):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    selected_sports = df_sports.loc[['Basketball', 'Football'], ['Wins', 'Losses']]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"selected_sports\": selected_sports}\n",
        "\n",
        "pandas_32()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj3EgX1e8pwI",
        "outputId": "fbcaad45-689c-45b0-e542-97832b8b745f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# From DataFrame `df_catalog`, select rows where 'Category' is 'Electronics' and save them to `electronics_catalog`.\n",
        "@check_pandas_33\n",
        "def pandas_33(df_catalog):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    electronics_catalog = df_catalog[df_catalog['Category'] == 'Electronics']\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"electronics_catalog\": electronics_catalog}\n",
        "\n",
        "pandas_33()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzgK7pN68pwI",
        "outputId": "e84f57ca-5fc4-4731-ca5e-5c4306a1cdf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# For DataFrame `df_movies`, perform boolean selection where 'Genre' is 'Action' and 'Budget' > 500000, then select 'Title' and 'Revenue' columns, storing result in `selected_movies`.\n",
        "@check_pandas_34\n",
        "def pandas_34(df_movies):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    selected_movies = df_movies.loc[(df_movies['Genre'] == 'Action') & (df_movies['Budget'] > 500000), ['Title', 'Revenue']]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"selected_movies\": selected_movies}\n",
        "\n",
        "pandas_34()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xmwLKEh8pwI"
      },
      "outputs": [],
      "source": [
        "from sigmoid_check.excalibur import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM9uJMKO8pwI",
        "outputId": "d893b2bf-6cbd-4084-e92c-9150d82d110e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Using .loc, slice DataFrame `df_plants` to include rows 'Rose' through 'Tulip' and store it in `flower_slice`.\n",
        "@check_pandas_35\n",
        "def pandas_35(df_plants):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    flower_slice = df_plants.loc['Rose':'Tulip']\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"flower_slice\": flower_slice}\n",
        "\n",
        "pandas_35()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz8lDh3R8pwI",
        "outputId": "99d73cd8-b97f-4120-a41e-6ae5e8e32f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use .iloc to slice DataFrame `df_students` to include the first three rows and the first two columns, saving them in `student_slice`.\n",
        "@check_pandas_36\n",
        "def pandas_36(df_students):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    student_slice = df_students.iloc[:3, :2]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"student_slice\": student_slice}\n",
        "\n",
        "pandas_36()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjXo5W8B8pwJ",
        "outputId": "772b5930-0aed-4fa1-8654-a37153bb0462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# From DataFrame `df_reports`, use a combination of .loc and .iloc to select rows 'R102' and 'R103' and the first three columns, storing it as `report_selection`.\n",
        "@check_pandas_37\n",
        "def pandas_37(df_reports):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    report_selection = df_reports.loc[['R102', 'R103']].iloc[:, :3]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"report_selection\": report_selection}\n",
        "\n",
        "pandas_37()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2fluDnG8pwL",
        "outputId": "65c69190-d29c-43b6-93aa-2ed8424f238c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Modify DataFrame `df_inventory` by setting all 'Quantity' to 50 for rows labeled 'InStock' and store the modified DataFrame as `inventory_modified`.\n",
        "@check_pandas_38\n",
        "def pandas_38(df_inventory):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    inventory_modified = df_inventory.copy()\n",
        "    inventory_modified.loc['InStock', 'Quantity'] = 50\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"inventory_modified\": inventory_modified}\n",
        "\n",
        "pandas_38()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lv5NTpNn8pwL",
        "outputId": "a690649b-bf23-4125-a9dd-5ce14a232267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Combine .loc and .iloc to modify rows 'R101' to 'R105' in 'df_revenue' setting the first column's value to 1000, storing it in `revenue_updated`.\n",
        "@check_pandas_39\n",
        "def pandas_39(df_revenue):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    revenue_updated = df_revenue.copy()\n",
        "    revenue_updated.loc['R101':'R105', revenue_updated.columns[0]] = 1000\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"revenue_updated\": revenue_updated}\n",
        "\n",
        "pandas_39()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3oPeYgM8pwL",
        "outputId": "b72ddaf2-7a0e-4aed-dab8-ab2e6f8c4c70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Using DataFrame `df_hierarchical_example`, demonstrate the use of .loc and .iloc on a DataFrame with a multiindex, saving the selection as `multiindex_selected`, selecting the row with index ('North', 'A') and column 'X'.\n",
        "@check_pandas_40\n",
        "def pandas_40(df_hierarchical_example):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    multiindex_selected = df_hierarchical_example.loc[('North', 'A'), 'X']\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"multiindex_selected\": multiindex_selected}\n",
        "\n",
        "pandas_40()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1rmHt2e8pwM",
        "outputId": "1de2ad1a-4d2f-4608-f998-e319f0e46bf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Concatenate DataFrames `df1` and `df2` horizontally and save the result as `concatenated_df_horizontal`.\n",
        "@check_pandas_41\n",
        "def pandas_41(df1, df2):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    concatenated_df_horizontal = pd.concat([df1, df2], axis=1)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"concatenated_df_horizontal\": concatenated_df_horizontal}\n",
        "\n",
        "pandas_41()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCpJ3KQw8pwM",
        "outputId": "7687269a-b750-4504-8f34-88a2fd73da0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Concatenate DataFrames `df_a` and `df_b` vertically, aligning by columns, and store the result in `concatenated_df_vertical`.\n",
        "@check_pandas_42\n",
        "def pandas_42(df_a, df_b):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    concatenated_df_vertical = pd.concat([df_a, df_b], axis=0)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"concatenated_df_vertical\": concatenated_df_vertical}\n",
        "\n",
        "pandas_42()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-sXXP6e8pwM",
        "outputId": "79fed9c3-b1a0-4729-f604-13b08306bdd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Merge DataFrames `df_left` and `df_right` on key 'ID', using outer method and store result in `merged_outer`.\n",
        "@check_pandas_43\n",
        "def pandas_43(df_left, df_right):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    merged_outer = pd.merge(df_left, df_right, on='ID', how='outer')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"merged_outer\": merged_outer}\n",
        "\n",
        "pandas_43()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vi8ifT608pwM",
        "outputId": "ed6ec882-ed66-4c0c-f67e-f61a5c5eb196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Perform a right merge on DataFrames `df_personal` and `df_contact` based on the key 'ContactID', saving it as `merged_right`.\n",
        "@check_pandas_44\n",
        "def pandas_44(df_personal, df_contact):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    merged_right = pd.merge(df_personal, df_contact, on='ContactID', how='right')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"merged_right\": merged_right}\n",
        "\n",
        "pandas_44()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC6Fpj4G8pwN",
        "outputId": "5bf177db-a104-41e7-abe1-f82de86ec530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Join DataFrames `df_main` and `df_additional` using an inner join, saving the result in `joined_inner`.\n",
        "@check_pandas_45\n",
        "def pandas_45(df_main, df_additional):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    joined_inner = df_main.join(df_additional, how='inner')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"joined_inner\": joined_inner}\n",
        "\n",
        "pandas_45()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqIhwfiF8pwN",
        "outputId": "c0a7ff65-0bb5-4023-de84-237a4a0388e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Conduct a left join on DataFrames `df_sales_main` and `df_sales_region` on 'RegionID', storing it as `joined_left`.\n",
        "@check_pandas_46\n",
        "def pandas_46(df_sales_main, df_sales_region):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    joined_left = df_sales_main.join(df_sales_region, how='left', on='RegionID')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"joined_left\": joined_left}\n",
        "\n",
        "pandas_46()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV_2eW988pwN",
        "outputId": "2bd3e207-7e14-48e6-9da4-3388ae139378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Group DataFrame `df_employee` by 'Department', calculating the average 'Salary' for each group and saving it as `avg_salary_by_department`.\n",
        "@check_pandas_47\n",
        "def pandas_47(df_employee):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    avg_salary_by_department = df_employee.groupby('Department')['Salary'].mean()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"avg_salary_by_department\": avg_salary_by_department}\n",
        "\n",
        "pandas_47()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIWa8D8r8pwN",
        "outputId": "76b2691f-7dc8-4f78-83e4-333dde20f519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Pivot DataFrame `df_orders` with 'OrderID' as index, 'Category' as columns, and 'Amount' as values, resulting in `pivoted_orders`.\n",
        "@check_pandas_48\n",
        "def pandas_48(df_orders):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    pivoted_orders = df_orders.pivot(index='OrderID', columns='Category', values='Amount')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"pivoted_orders\": pivoted_orders}\n",
        "\n",
        "pandas_48()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBOLcDyx8pwN",
        "outputId": "f4459b61-2143-4c4b-fa2e-92bcb925518d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Utilize crosstab to get a frequency table of 'Region' and 'ProductType' categories from `df_business`, storing the result as `region_product_crosstab`.\n",
        "@check_pandas_49\n",
        "def pandas_49(df_business):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    region_product_crosstab = pd.crosstab(df_business['Region'], df_business['ProductType'])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"region_product_crosstab\": region_product_crosstab}\n",
        "\n",
        "pandas_49()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSn3-sxS8pwN",
        "outputId": "b0f1f754-5516-40f0-ae0e-11786efd4b3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Reshape DataFrame `df_energy` from wide to long format using melt, and store the result in `melted_energy`.\n",
        "@check_pandas_50\n",
        "def pandas_50(df_energy):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    melted_energy = pd.melt(df_energy, id_vars=['Year'], var_name='Type', value_name='Energy')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"melted_energy\": melted_energy}\n",
        "\n",
        "pandas_50()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMUX88FU8pwO",
        "outputId": "0f1ccbf8-d3d7-449e-e0ad-ec71303abee0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Using DataFrame `df_product_sales`, change its structure by applying a pivot operation with 'ProductID' being the index, columns as 'Month', and 'Sales' as values, storing the result in `pivoted_sales`.\n",
        "@check_pandas_51\n",
        "def pandas_51(df_product_sales):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    pivoted_sales = df_product_sales.pivot(index='ProductID', columns='Month', values='Sales')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"pivoted_sales\": pivoted_sales}\n",
        "\n",
        "pandas_51()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHngDL7p8pwO",
        "outputId": "a6c6fa4f-7bf1-4697-bc0c-b52912663ef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a pandas DataFrame `df_date_range` using a date range starting from '2022-01-01' to '2023-01-01', frequency of 'MS', with columns ['Sales', 'Profit'] filled with zeros.\n",
        "@check_pandas_52\n",
        "def pandas_52():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_date_range = pd.DataFrame(0, index=pd.date_range(start='2022-01-01', end='2023-01-01', freq='MS'), columns=['Sales', 'Profit'])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_date_range\": df_date_range}\n",
        "\n",
        "pandas_52()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOM-bBbn8pwO",
        "outputId": "e274fbbd-aa4c-4a83-b51c-33ddcf6dc7f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Extract the year and month for each entry in DataFrame `df_date_series` with a DateTimeIndex, storing them in `years` and `months` respectively.\n",
        "@check_pandas_53\n",
        "def pandas_53(df_date_series):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    years = df_date_series.index.year\n",
        "    months = df_date_series.index.month\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"years\": years, \"months\": months}\n",
        "\n",
        "pandas_53()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3lRP6BB8pwO",
        "outputId": "54a8ef94-0601-4cb7-8b25-b3dc8d3d7634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_9528\\2127553736.py:8: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  quarterly_series = df_time_series.resample('Q').sum()\n"
          ]
        }
      ],
      "source": [
        "# Resample DataFrame `df_time_series` to quarterly frequency, taking the sum, and store the resulting series in `quarterly_series`.\n",
        "@check_pandas_54\n",
        "def pandas_54(df_time_series):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    quarterly_series = df_time_series.resample('Q').sum()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"quarterly_series\": quarterly_series}\n",
        "\n",
        "pandas_54()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCei3Qdf8pwO",
        "outputId": "d38e5703-9acb-485b-8a44-34a24974ecb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Apply a rolling window of 7 days for the DataFrame `df_metrics`, and calculate the mean, storing it in `rolling_mean_metrics`.\n",
        "@check_pandas_55\n",
        "def pandas_55(df_metrics):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    rolling_mean_metrics = df_metrics.rolling(window=7).mean()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"rolling_mean_metrics\": rolling_mean_metrics}\n",
        "\n",
        "pandas_55()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef5SY_L08pwO",
        "outputId": "4d2f86ec-4637-47dc-92ab-2f2421d88c15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Apply the function `np.log1p` to the column 'Revenue' in DataFrame `df_financial_data`, storing the updated data in `logged_df`.\n",
        "@check_pandas_56\n",
        "def pandas_56(df_financial_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    logged_df = df_financial_data.copy()\n",
        "    logged_df['Revenue'] = np.log1p(logged_df['Revenue'])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"logged_df\": logged_df}\n",
        "\n",
        "pandas_56()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkCx7x2-8pwO",
        "outputId": "b60ccc8e-654c-4206-e64b-43bd6e830147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Optimize memory usage of DataFrame `df_large` by converting column 'ID' to int32 and store as `optimized_df`.\n",
        "@check_pandas_57\n",
        "def pandas_57(df_large):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    optimized_df = df_large.copy()\n",
        "    optimized_df['ID'] = optimized_df['ID'].astype('int32')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"optimized_df\": optimized_df}\n",
        "\n",
        "pandas_57()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI6xQru08pwP",
        "outputId": "6578f6e4-a306-46d1-bbc6-9df48e8aa7b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Convert data types of 'Price' in DataFrame `df_items` from float64 to float32 for memory efficiency, saving the result as `optimized_items`.\n",
        "@check_pandas_58\n",
        "def pandas_58(df_items):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    optimized_items = df_items.copy()\n",
        "    optimized_items['Price'] = optimized_items['Price'].astype('float32')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"optimized_items\": optimized_items}\n",
        "\n",
        "pandas_58()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJIg4d2D8pwP",
        "outputId": "509c1b3f-b084-450c-b2cb-48a252042758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Remove duplicate entries from DataFrame `df_database` and store the cleaned DataFrame as `unique_database`.\n",
        "@check_pandas_59\n",
        "def pandas_59(df_database):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    unique_database = df_database.drop_duplicates()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"unique_database\": unique_database}\n",
        "\n",
        "pandas_59()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHvu_Q-b8pwP",
        "outputId": "90e2eace-39ac-4c14-afa7-3df0d194f2e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Perform string operation by converting all entries in the 'Names' column of `df_attendees` to uppercase, storing the resulting DataFrame as `uppercase_attendees`.\n",
        "@check_pandas_60\n",
        "def pandas_60(df_attendees):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    uppercase_attendees = df_attendees.copy()\n",
        "    uppercase_attendees['Names'] = uppercase_attendees['Names'].str.upper()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"uppercase_attendees\": uppercase_attendees}\n",
        "\n",
        "pandas_60()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut-U9y5a8pwP",
        "outputId": "69ba68ea-b5cb-441e-9a57-56e2b9929459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Select rows from DataFrame `df_students` using the query method to find students with 'Score' greater than 85, storing the result as `high_scorers`.\n",
        "@check_pandas_61\n",
        "def pandas_61(df_students):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    high_scorers = df_students.query('Score > 85')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"high_scorers\": high_scorers}\n",
        "\n",
        "pandas_61()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAhLJrOI8pwP",
        "outputId": "e0109590-6914-46c0-b0e6-6a1b67d6152e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# In DataFrame `df_results`, group by 'Team', apply custom function to rank 'Score' in descending order, and store the result in `ranked_teams`.\n",
        "@check_pandas_62\n",
        "def pandas_62(df_results):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    ranked_teams = df_results.groupby('Team')['Score'].apply(lambda x: x.rank(ascending=False))\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"ranked_teams\": ranked_teams}\n",
        "\n",
        "pandas_62()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmYTcOnX8pwP",
        "outputId": "82838161-4250-4063-c1c3-5e65107864bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Perform a aggregation on DataFrame `df_data_group` for 'City' using a custom function that finds the range of 'Temperature', storing as `temperature_range`.\n",
        "@check_pandas_63\n",
        "def pandas_63(df_data_group):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    temperature_range = df_data_group.groupby('City')['Temperature'].agg(lambda x: x.max() - x.min())\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"temperature_range\": temperature_range}\n",
        "\n",
        "pandas_63()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFSjJKvL8pwP",
        "outputId": "aefe32a9-848f-42f0-9c87-1f84fe85c359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use vectorized operations to add 10 to every element in DataFrame `df_numeric`, saving the result as `adjusted_numeric`.\n",
        "@check_pandas_64\n",
        "def pandas_64(df_numeric):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    adjusted_numeric = df_numeric + 10\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"adjusted_numeric\": adjusted_numeric}\n",
        "\n",
        "pandas_64()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlU3N7IX8pwP",
        "outputId": "e500cf9f-8da3-4da2-f7d3-90883ba8f8cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Process DataFrame `df_sales_timezones` to convert the 'Timestamp' to a timezone-aware datetime, setting the timezone to 'UTC', and save as `timezone_aware_sales`.\n",
        "@check_pandas_65\n",
        "def pandas_65(df_sales_timezones):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_sales_timezones['Timestamp'] = pd.to_datetime(df_sales_timezones['Timestamp'], utc=True)\n",
        "    timezone_aware_sales = df_sales_timezones\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"timezone_aware_sales\": timezone_aware_sales}\n",
        "\n",
        "pandas_65()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tXit44L8pwQ",
        "outputId": "102448e7-12cb-401a-fb9e-0cb68d6ba5c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_9528\\3131592359.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  df_customer_reviews = pd.read_json(json_input_string)\n"
          ]
        }
      ],
      "source": [
        "# Create a pandas DataFrame `df_customer_reviews` from a JSON string `json_input_string`.\n",
        "@check_pandas_66\n",
        "def pandas_66(json_input_string):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_customer_reviews = pd.read_json(json_input_string)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_customer_reviews\": df_customer_reviews}\n",
        "\n",
        "pandas_66()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf8SNm4q8pwQ",
        "outputId": "585d02ce-6ece-4ab6-9472-f806cd989cc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Given a pandas Series `series_temp_investments`, access specific elements from custom indices ['A1', 'B2', 'C3'] and save them to `selected_investments`.\n",
        "@check_pandas_67\n",
        "def pandas_67(series_temp_investments):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    selected_investments = series_temp_investments.loc[['A1', 'B2', 'C3']]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"selected_investments\": selected_investments}\n",
        "\n",
        "pandas_67()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPlutlvP8pwQ",
        "outputId": "cff67f73-702d-4f79-9653-dffa93d5838d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Slice pandas Series `series_temp_readings` to return every second element, storing the result in `temp_slice_even`.\n",
        "@check_pandas_68\n",
        "def pandas_68(series_temp_readings):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    temp_slice_even = series_temp_readings[::2]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"temp_slice_even\": temp_slice_even}\n",
        "\n",
        "pandas_68()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t9hZ40U8pwQ",
        "outputId": "138ac2ea-07cc-4e57-e901-aef2413ba58c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# From a list of dictionaries `sensor_data_list`, create a DataFrame named `df_sensor_readings` with custom column names ['SensorID', 'Temperature', 'Humidity'].\n",
        "@check_pandas_69\n",
        "def pandas_69(sensor_data_list):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_sensor_readings = pd.DataFrame(sensor_data_list, columns=['SensorID', 'Temperature', 'Humidity'])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_sensor_readings\": df_sensor_readings}\n",
        "\n",
        "pandas_69()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADwvE0zF8pwQ",
        "outputId": "267f6dfa-e14d-4626-9a74-efab23250513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Access and display the first 10 elements of Series `series_large_dataset`, storing them in `top_ten_elements`.\n",
        "@check_pandas_70\n",
        "def pandas_70(series_large_dataset):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    top_ten_elements = series_large_dataset.head(10)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"top_ten_elements\": top_ten_elements}\n",
        "\n",
        "pandas_70()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grH9LLGF8pwQ",
        "outputId": "693d2e2c-78a0-4a22-c11c-7694dd5986f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use the DataFrame `df_population_data` to extract and store the indices in a variable `population_indices`.\n",
        "@check_pandas_71\n",
        "def pandas_71(df_population_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    population_indices = df_population_data.index\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"population_indices\": population_indices}\n",
        "\n",
        "pandas_71()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-mu7pn48pwQ",
        "outputId": "2d960b04-a5da-401f-c2ec-7029e6400b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Combine DataFrames `df_financial_2021` and `df_financial_2020` vertically, so that rows from 2021 follow those of 2020, storing result in `combined_financials`.\n",
        "@check_pandas_72\n",
        "def pandas_72(df_financial_2021, df_financial_2020):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    combined_financials = pd.concat([df_financial_2020, df_financial_2021], axis=0)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"combined_financials\": combined_financials}\n",
        "\n",
        "pandas_72()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZY_YRFM8pwQ",
        "outputId": "39e1538e-f981-44c5-9de6-56a1a43578dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Merge DataFrames `df_clients` and `df_orders` with a common key 'ClientID' using the 'inner' join method, and save the result as `client_orders`.\n",
        "@check_pandas_73\n",
        "def pandas_73(df_clients, df_orders):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    client_orders = pd.merge(df_clients, df_orders, on='ClientID', how='inner')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"client_orders\": client_orders}\n",
        "\n",
        "pandas_73()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0goYW29M8pwQ",
        "outputId": "c7be06b0-52a1-41ad-8454-bd89b57b49a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# From DataFrame `df_commodity_prices`, locate the element where 'Commodity' is 'Gold' and 'PriceDate' is '2023-06-01', storing it in `gold_price`.\n",
        "@check_pandas_74\n",
        "def pandas_74(df_commodity_prices):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    gold_price = df_commodity_prices.loc[(df_commodity_prices['Commodity'] == 'Gold') & (df_commodity_prices['PriceDate'] == '2023-06-01')]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"gold_price\": gold_price}\n",
        "\n",
        "pandas_74()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVLrLe0Z8pwR",
        "outputId": "fa1dcf14-aa59-44d9-a24e-8d05dce0703a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use boolean indexing on DataFrame `df_sales_performance` to extract rows where 'Quarter' is Q1 and 'Year' >= 2022, saving the result in `performance_q1_2022`.\n",
        "@check_pandas_75\n",
        "def pandas_75(df_sales_performance):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    performance_q1_2022 = df_sales_performance[(df_sales_performance['Quarter'] == 'Q1') & (df_sales_performance['Year'] >= 2022)]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"performance_q1_2022\": performance_q1_2022}\n",
        "\n",
        "pandas_75()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcgysIbG8pwR",
        "outputId": "c9b1b4d7-2473-43af-c4d9-477f64d8dc09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Slice DataFrame `df_international_customers` to include rows 'France' to 'Italy' using their index labels and save it in `european_customers`.\n",
        "@check_pandas_76\n",
        "def pandas_76(df_international_customers):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    european_customers = df_international_customers.loc['France':'Italy']\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"european_customers\": european_customers}\n",
        "\n",
        "pandas_76()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQ5itiby8pwR",
        "outputId": "45230d6a-665c-4737-c772-e2de0a542c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Modify DataFrame `df_shipping_list` by setting the 'CollectionDate' column of all rows before '2023-08-01' to NaT, storing the modified DataFrame as `adjusted_shipping`.\n",
        "@check_pandas_77\n",
        "def pandas_77(df_shipping_list):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    adjusted_shipping = df_shipping_list.copy()\n",
        "    adjusted_shipping.loc[adjusted_shipping['CollectionDate'] < '2023-08-01', 'CollectionDate'] = pd.NaT\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"adjusted_shipping\": adjusted_shipping}\n",
        "\n",
        "pandas_77()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WajoYb48pwR",
        "outputId": "aae64e65-f02b-4c05-bca9-45c5cd5e4e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Merge DataFrames `df_employee_roles` and `df_role_salaries` on 'RoleID', performing a left merge and storing result as `employee_salary_details`.\n",
        "@check_pandas_78\n",
        "def pandas_78(df_employee_roles, df_role_salaries):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    employee_salary_details = pd.merge(df_employee_roles, df_role_salaries, on='RoleID', how='left')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"employee_salary_details\": employee_salary_details}\n",
        "\n",
        "pandas_78()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQ_t1B1w8pwR",
        "outputId": "b913f669-a28f-4719-995a-b4f158500a58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Group DataFrame `df_class_scores` by 'Class' and calculate the maximum 'Score' for each class, saving the result as `max_class_scores`.\n",
        "@check_pandas_79\n",
        "def pandas_79(df_class_scores):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    max_class_scores = df_class_scores.groupby('Class')['Score'].max()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"max_class_scores\": max_class_scores}\n",
        "\n",
        "pandas_79()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2MseFgq8pwR",
        "outputId": "94194315-f133-42be-df80-018e3bcbe0b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Pivot DataFrame `df_sales_regions` with 'Region' as rows and 'Quarter' as columns, aggregating 'Sales' values, into `sales_pivot`.\n",
        "@check_pandas_80\n",
        "def pandas_80(df_sales_regions):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    sales_pivot = df_sales_regions.pivot(index='Region', columns='Quarter', values='Sales')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sales_pivot\": sales_pivot}\n",
        "\n",
        "pandas_80()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZSNSbPz8pwR",
        "outputId": "228aeb6f-4a7b-48e2-ccaa-fba48af17659"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Utilize a crosstab of 'CustomerType' and 'Region' from DataFrame `df_customer_data`, storing the result as `customer_region_crosstab`.\n",
        "@check_pandas_81\n",
        "def pandas_81(df_customer_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    customer_region_crosstab = pd.crosstab(df_customer_data['CustomerType'], df_customer_data['Region'])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"customer_region_crosstab\": customer_region_crosstab}\n",
        "\n",
        "pandas_81()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxsONXzS8pwR",
        "outputId": "0d8d23aa-29cb-4f43-fb87-f9c18d73096b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Reshape DataFrame `df_expenses` to long format, using melt function, resulting in `melted_expenses`.\n",
        "@check_pandas_82\n",
        "def pandas_82(df_expenses):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    melted_expenses = pd.melt(df_expenses, id_vars='Category', var_name='Month', value_name='Amount')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"melted_expenses\": melted_expenses}\n",
        "\n",
        "pandas_82()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzi9v6ay8pwS",
        "outputId": "01ee8fab-6f7c-419d-d203-ef4a44ab9661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use a pivot_table on DataFrame `df_contact_events` with 'ContactID' as index, 'EventType' as columns, and 'EventTimestamp' as values, stored in `pivoted_events`.\n",
        "@check_pandas_83\n",
        "def pandas_83(df_contact_events):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    pivoted_events = df_contact_events.pivot_table(index='ContactID', columns='EventType', values='EventTimestamp', aggfunc='first')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"pivoted_events\": pivoted_events}\n",
        "\n",
        "pandas_83()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d12S0Xh98pwS",
        "outputId": "dc02710a-187c-4486-f15a-69115c79532e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame `df_time_events` using a DateTimeIndex from a 'start' of '2023-01-01', 'end' of '2023-12-31', and a daily frequency.\n",
        "@check_pandas_84\n",
        "def pandas_84():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_time_events = pd.DataFrame(index=pd.date_range(start='2023-01-01', end='2023-12-31', freq='D'))\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_time_events\": df_time_events}\n",
        "\n",
        "pandas_84()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvCTZOuP8pwS",
        "outputId": "a8491a16-a4da-40a1-d792-c9d6fb9ca866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Convert the time zone of the 'datetime' column in DataFrame `df_events`, from UTC to US/Eastern, storing result as `tz_adjusted_events`.\n",
        "@check_pandas_85\n",
        "def pandas_85(df_events):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    tz_adjusted_events = df_events.copy()\n",
        "    tz_adjusted_events['datetime'] = tz_adjusted_events['datetime'].dt.tz_convert('US/Eastern')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"tz_adjusted_events\": tz_adjusted_events}\n",
        "\n",
        "pandas_85()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAEYiqsD8pwS",
        "outputId": "d80cfed5-fe05-41dc-a500-881dc1e85632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Calculate the weekly rolling sum on DataFrame `df_financial_changes` for 'ChangeAmount', storing the result in `weekly_rolling_sum`.\n",
        "@check_pandas_86\n",
        "def pandas_86(df_financial_changes):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    weekly_rolling_sum = df_financial_changes['ChangeAmount'].rolling(window=7).sum()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"weekly_rolling_sum\": weekly_rolling_sum}\n",
        "\n",
        "pandas_86()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQ8w7bF48pwS",
        "outputId": "e019d338-03db-448e-9092-3eb1fafb50f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use the apply function along with a custom lambda to multiply the 'Rating' column by 2 in DataFrame `df_movie_ratings`, saving it as `scaled_ratings`.\n",
        "@check_pandas_87\n",
        "def pandas_87(df_movie_ratings):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    scaled_ratings = df_movie_ratings.copy()\n",
        "    scaled_ratings['Rating'] = scaled_ratings['Rating'].apply(lambda x: x * 2)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"scaled_ratings\": scaled_ratings}\n",
        "\n",
        "pandas_87()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjubxL918pwS",
        "outputId": "62092d4d-e79e-4028-caf9-3c3145aa826d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Convert DataFrame `df_sequential` column 'Order' from int64 to int16 for memory efficiency, saving result as `optimized_sequential`.\n",
        "@check_pandas_88\n",
        "def pandas_88(df_sequential):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    optimized_sequential = df_sequential.copy()\n",
        "    optimized_sequential['Order'] = optimized_sequential['Order'].astype('int16')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"optimized_sequential\": optimized_sequential}\n",
        "\n",
        "pandas_88()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUi2JqoW8pwS",
        "outputId": "b020b81f-f2f3-4f19-d2f3-54eba25f03f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Remove duplicate entries based on 'Email' in DataFrame `df_email_contacts`, storing deduplicated DataFrame as `unique_email_contacts`.\n",
        "@check_pandas_89\n",
        "def pandas_89(df_email_contacts):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    unique_email_contacts = df_email_contacts.drop_duplicates(subset='Email')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"unique_email_contacts\": unique_email_contacts}\n",
        "\n",
        "pandas_89()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnWLgPJE8pwS",
        "outputId": "8f5d09ea-d34c-481f-a3c6-cfe4c30426a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Perform string operation by replacing all occurrences of 'Inc.' with 'Incorporated' in the 'Company_Name' column of `df_business_registry`, storing result in `updated_business_registry`.\n",
        "@check_pandas_90\n",
        "def pandas_90(df_business_registry):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    updated_business_registry = df_business_registry.copy()\n",
        "    updated_business_registry['Company_Name'] = updated_business_registry['Company_Name'].str.replace('Inc.', 'Incorporated')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"updated_business_registry\": updated_business_registry}\n",
        "\n",
        "pandas_90()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOmZHUi08pwS",
        "outputId": "a3d87e7c-98b2-4038-9317-e933e3f6cfb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Select entries from DataFrame `df_jobs` with 'Role' ending in 'Engineer' using the query method, saving result as `engineer_roles`.\n",
        "@check_pandas_91\n",
        "def pandas_91(df_jobs):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    engineer_roles = df_jobs.query('Role.str.endswith(\"Engineer\")', engine='python')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"engineer_roles\": engineer_roles}\n",
        "\n",
        "pandas_91()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF1TK7QX8pwT",
        "outputId": "1260be00-ca25-4bb7-abfe-1b9e2513a163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Group DataFrame `df_market_data` by 'Sector' and aggregate 'MarketCap' using the custom function to find the median, saving in `median_market_cap`.\n",
        "@check_pandas_92\n",
        "def pandas_92(df_market_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    median_market_cap = df_market_data.groupby('Sector')['MarketCap'].agg(lambda x: x.median())\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"median_market_cap\": median_market_cap}\n",
        "\n",
        "pandas_92()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxUonZXl8pwT",
        "outputId": "af960e44-bfd2-425b-9360-fa977064a05e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use vectorized operations on DataFrame `df_portfolio`, to multiply every element in 'Shares' column by its corresponding 'Price', saving the result in `portfolio_value`.\n",
        "@check_pandas_93\n",
        "def pandas_93(df_portfolio):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    portfolio_value = df_portfolio['Shares'] * df_portfolio['Price']\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"portfolio_value\": portfolio_value}\n",
        "\n",
        "pandas_93()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1sZb8PP8pwT",
        "outputId": "4990c3e0-c36c-402d-886b-e55d5c7ca88b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Add a 'ProfitMargin' column to DataFrame `df_sales_figures`, calculated as ('Profit' / 'Revenue') * 100 using vectorized operations, saving as `sales_with_margin`.\n",
        "@check_pandas_94\n",
        "def pandas_94(df_sales_figures):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    sales_with_margin = df_sales_figures.copy()\n",
        "    sales_with_margin['ProfitMargin'] = (sales_with_margin['Profit'] / sales_with_margin['Revenue']) * 100\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sales_with_margin\": sales_with_margin}\n",
        "\n",
        "pandas_94()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXeJ2dTg8pwT",
        "outputId": "42b08068-740e-4293-b2e6-6738abdac9af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Sort DataFrame `df_graduates` by 'GPA' in descending order, saving sorted DataFrame as `sorted_graduates`.\n",
        "@check_pandas_95\n",
        "def pandas_95(df_graduates):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    sorted_graduates = df_graduates.sort_values(by='GPA', ascending=False)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sorted_graduates\": sorted_graduates}\n",
        "\n",
        "pandas_95()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85KED7VM8pwT",
        "outputId": "b9aa6959-27bb-44f9-b023-12873ac48730"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Filter DataFrame `df_emissions` for 'Country' is 'USA' and 'Year' before 2000 using boolean conditions, saving result as `us_emissions_pre2000`.\n",
        "@check_pandas_96\n",
        "def pandas_96(df_emissions):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    us_emissions_pre2000 = df_emissions[(df_emissions['Country'] == 'USA') & (df_emissions['Year'] < 2000)]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"us_emissions_pre2000\": us_emissions_pre2000}\n",
        "\n",
        "pandas_96()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnBvLtsR8pwT",
        "outputId": "3bcfed12-8d64-4f26-d150-c0378dae9e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Calculate the cumulative sum of 'Purchases' in DataFrame `df_shopper_history` grouped by 'Year', storing the result in `yearly_cumulative_purchases`.\n",
        "@check_pandas_97\n",
        "def pandas_97(df_shopper_history):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    yearly_cumulative_purchases = df_shopper_history.groupby('Year')['Purchases'].cumsum()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"yearly_cumulative_purchases\": yearly_cumulative_purchases}\n",
        "\n",
        "pandas_97()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1MGL3QQ8pwT",
        "outputId": "c566c4e5-7666-4a81-952a-8d9cb7cc491c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame `df_series_fan_following` with integers between 1000 and 5000 equally separated, indexed by monthly dates starting from '2022-01-01', till '2022-05-01', with column name 'Fans' and frequency 'MS'.\n",
        "@check_pandas_98\n",
        "def pandas_98():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_series_fan_following = pd.DataFrame(np.arange(1000, 5001, 1000), index=pd.date_range(start='2022-01-01', end='2022-05-01', freq='MS'), columns = ['Fans'])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_series_fan_following\": df_series_fan_following}\n",
        "\n",
        "pandas_98()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1VLDAmK8pwT",
        "outputId": "de2f69d2-9605-41d6-d08c-9804569ddc7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Calculate difference in 'ClosingPrice' from previous day in DataFrame `df_stock_prices`, storing result as `closing_price_diff`.\n",
        "@check_pandas_99\n",
        "def pandas_99(df_stock_prices):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    closing_price_diff = df_stock_prices['ClosingPrice'].diff()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"closing_price_diff\": closing_price_diff}\n",
        "\n",
        "pandas_99()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBC8tEQw8pwT",
        "outputId": "47188b07-f65c-4a09-e1c1-9493efe3290b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Merge DataFrames `df_social_media_insights` and `df_campaign_performance` on 'CampaignID', using outer method saving result as `merged_campaign_data`.\n",
        "@check_pandas_100\n",
        "def pandas_100(df_social_media_insights, df_campaign_performance):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    merged_campaign_data = pd.merge(df_social_media_insights, df_campaign_performance, on='CampaignID', how='outer')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"merged_campaign_data\": merged_campaign_data}\n",
        "\n",
        "pandas_100()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}