{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU-w5VOIGD2f"
      },
      "outputs": [],
      "source": [
        "# make sure you have the latest version of sigmoid_check installed by running pip install sigmoid_check --upgrade\n",
        "from sigmoid_check.excalibur import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwWwEhvBGD2g",
        "outputId": "5937dbf4-fe15-4618-b985-931c8cff2683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Extract DataFrame `df_social_media_metrics` subset for rows where 'Likes' exceed 'Shares' and store it in `highly_liked_posts`.\n",
        "@check_pandas_101\n",
        "def pandas_101(df_social_media_metrics):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    highly_liked_posts = df_social_media_metrics[df_social_media_metrics['Likes'] > df_social_media_metrics['Shares']]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"highly_liked_posts\": highly_liked_posts}\n",
        "\n",
        "pandas_101()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSRkUkC1GD2g",
        "outputId": "ae607e98-9e44-449c-8b7e-cd815584d91a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_product_info` to group by 'Category', computing the minimum 'Price' for each category, storing result as `min_price_by_category`.\n",
        "@check_pandas_102\n",
        "def pandas_102(df_product_info):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    min_price_by_category = df_product_info.groupby('Category')['Price'].min()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"min_price_by_category\": min_price_by_category}\n",
        "\n",
        "pandas_102()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5m_hssDGD2h",
        "outputId": "f82c9b22-63e8-4583-c263-84b5867fd3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Apply datetime filtering on `df_online_sessions` to store sessions in the month of January 2023 in variable `january_sessions` based on 'SessionStart'.\n",
        "@check_pandas_103\n",
        "def pandas_103(df_online_sessions):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_online_sessions['SessionStart'] = pd.to_datetime(df_online_sessions['SessionStart'])\n",
        "    january_sessions = df_online_sessions[(df_online_sessions['SessionStart'].dt.year == 2023) & (df_online_sessions['SessionStart'].dt.month == 1)]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"january_sessions\": january_sessions}\n",
        "\n",
        "pandas_103()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccnNDCCsGD2h",
        "outputId": "e6c529ca-cef4-4bcf-d946-014055a6b0c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_employee_entries` and fill NA in 'EntryTime' with '08:00 AM', storing the result in `filled_employee_entries`.\n",
        "@check_pandas_104\n",
        "def pandas_104(df_employee_entries):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    filled_employee_entries = df_employee_entries.fillna({'EntryTime': '08:00 AM'})\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"filled_employee_entries\": filled_employee_entries}\n",
        "\n",
        "pandas_104()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtju7UeZGD2h",
        "outputId": "abedd463-a246-442b-b98e-18c88e877ee5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Drop all columns with any NA values in DataFrame `df_transaction_records`, storing cleaned version as `non_na_transactions`.\n",
        "@check_pandas_105\n",
        "def pandas_105(df_transaction_records):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    non_na_transactions = df_transaction_records.dropna(axis=1)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"non_na_transactions\": non_na_transactions}\n",
        "\n",
        "pandas_105()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGFLMSd7GD2h",
        "outputId": "565ae132-3802-4fa7-cd15-d6a3508e5cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a Series `series_ascending` from a list of numbers [1, 2, 3, 4, 5], using these values as the indices as well.\n",
        "@check_pandas_106\n",
        "def pandas_106():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    series_ascending = pd.Series([1, 2, 3, 4, 5], index=[1, 2, 3, 4, 5])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"series_ascending\": series_ascending}\n",
        "\n",
        "pandas_106()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RoH_8W5GD2i",
        "outputId": "4ae49375-b131-4fbf-ae5f-b9212c799bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use the query method on DataFrame `df_financial_audit` to extract entries with 'Audit' == 'Complete' and 'Amount' > 10000, saving it as `completed_audits`.\n",
        "@check_pandas_107\n",
        "def pandas_107(df_financial_audit):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    completed_audits = df_financial_audit.query(\"Audit == 'Complete' and Amount > 10000\")\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"completed_audits\": completed_audits}\n",
        "\n",
        "pandas_107()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My17BW3XGD2i",
        "outputId": "c137895a-e59f-42b1-8993-01074d0fe776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a custom `percent_round` function and apply it to round the 'Progress' column in DataFrame `df_student_projects` to the nearest ten, storing result as `rounded_progress`.\n",
        "@check_pandas_108\n",
        "def pandas_108(df_student_projects):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def percent_round(x):\n",
        "        return round(x / 10) * 10\n",
        "\n",
        "    rounded_progress = df_student_projects.copy()\n",
        "    rounded_progress['Progress'] = rounded_progress['Progress'].apply(percent_round)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"rounded_progress\": rounded_progress}\n",
        "\n",
        "pandas_108()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpt-_7ycGD2i",
        "outputId": "9b1c2688-de0c-46bd-84ff-b4dba04be60e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Extract the elements starting from the 10th index to the 20th index from `df_user_activity`, storing the result in `sampled_user_activity`.\n",
        "@check_pandas_109\n",
        "def pandas_109(df_user_activity):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    sampled_user_activity = df_user_activity.iloc[10:20]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sampled_user_activity\": sampled_user_activity}\n",
        "\n",
        "pandas_109()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w-tvTEhGD2i",
        "outputId": "906918e3-6ec6-4e72-c31d-12de94ca6d9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use advanced indexing to set all negative values in DataFrame `df_temperature_fluctuations` to zero, storing corrected DataFrame as `non_negative_temperatures`.\n",
        "@check_pandas_110\n",
        "def pandas_110(df_temperature_fluctuations):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    non_negative_temperatures = df_temperature_fluctuations.copy()\n",
        "    non_negative_temperatures[non_negative_temperatures < 0] = 0\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"non_negative_temperatures\": non_negative_temperatures}\n",
        "\n",
        "pandas_110()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJz64w3vGD2i",
        "outputId": "c26857e2-1a78-42ae-8128-c24de5b00874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# With DataFrame `df_fleet_inventory`, allocate memory efficiency by converting 'Year' column to category, saving the result as `efficient_fleet_inventory`.\n",
        "@check_pandas_111\n",
        "def pandas_111(df_fleet_inventory):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    efficient_fleet_inventory = df_fleet_inventory.copy()\n",
        "    efficient_fleet_inventory['Year'] = efficient_fleet_inventory['Year'].astype('category')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"efficient_fleet_inventory\": efficient_fleet_inventory}\n",
        "\n",
        "pandas_111()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFsVbssTGD2i",
        "outputId": "4f82a211-8b41-4a67-ee85-d1e1084b5612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_respiratory_data` to calculate cumulative maximum of 'Pulse' within groups of 'PatientID', storing it as `grouped_cumulative_max`.\n",
        "@check_pandas_112\n",
        "def pandas_112(df_respiratory_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    grouped_cumulative_max = df_respiratory_data.groupby('PatientID')['Pulse'].cummax()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"grouped_cumulative_max\": grouped_cumulative_max}\n",
        "\n",
        "pandas_112()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD2N9Ba_GD2j",
        "outputId": "794c9bc1-c0a2-4825-e789-d94852bb86de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Group DataFrame `df_weather_statistics` and apply aggregation to find both 'mean' and 'std' of 'Temperature', storing multi-aggregate result as `weather_stats`.\n",
        "@check_pandas_113\n",
        "def pandas_113(df_weather_statistics):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    weather_stats = df_weather_statistics.groupby('Location')['Temperature'].agg(['mean', 'std']).reset_index()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"weather_stats\": weather_stats}\n",
        "\n",
        "pandas_113()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAxmkHmgGD2j",
        "outputId": "430a56ae-f618-4943-a866-1cfed08cb988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a hierarchical index on DataFrame `df_multilayer_data` using [('Region', 'State')], saving the result as `hierarchical_multilayer`.\n",
        "@check_pandas_114\n",
        "def pandas_114(df_multilayer_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    hierarchical_multilayer = df_multilayer_data.set_index(['Region', 'State'])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"hierarchical_multilayer\": hierarchical_multilayer}\n",
        "\n",
        "pandas_114()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHAL9geiGD2j",
        "outputId": "1187ebbe-5382-4a35-e626-f4c4451f76c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Calculate the exponential moving average with a span of 10 on the 'Close' column in DataFrame `df_market_activity`, storing to `ema_market_activity`.\n",
        "@check_pandas_115\n",
        "def pandas_115(df_market_activity):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    ema_market_activity = df_market_activity['Close'].ewm(span=10).mean()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"ema_market_activity\": ema_market_activity}\n",
        "\n",
        "pandas_115()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kj67h76MGD2j",
        "outputId": "b09ebc3d-634f-4451-c445-1d494448f74e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_9392\\2313963970.py:11: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  }, index=pd.date_range('2023-01-01', periods=12, freq='M'))\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame `df_temperature_readings` for two sensors over the year using monthly datetime index, with lineaerly increasing temperature values from 20 to 30 for Sensor1 and 15 to 25 for Sensor2.\n",
        "@check_pandas_116\n",
        "def pandas_116():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_temperature_readings = pd.DataFrame({\n",
        "        'Sensor1': np.linspace(20, 30, 12),\n",
        "        'Sensor2': np.linspace(15, 25, 12)\n",
        "    }, index=pd.date_range('2023-01-01', periods=12, freq='M'))\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_temperature_readings\": df_temperature_readings}\n",
        "\n",
        "pandas_116()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eO9YqrmoGD2j",
        "outputId": "1b39eb1b-135f-4e88-8296-f944bc7cdfc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_sales_tiers` to add a 'SalesTier' column assigned by binning the 'Sales' column into 'Low', 'Medium', and 'High' categories based on [0, 5000, 10000, 15000] bins, storing as `tiered_sales`.\n",
        "@check_pandas_117\n",
        "def pandas_117(df_sales_tiers):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    tiered_sales = df_sales_tiers.copy()\n",
        "    tiered_sales['SalesTier'] = pd.cut(tiered_sales['Sales'], bins=[0, 5000, 10000, 15000], labels=['Low', 'Medium', 'High'])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"tiered_sales\": tiered_sales}\n",
        "\n",
        "pandas_117()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsqaI6cYGD2j",
        "outputId": "dc5f31ab-92c1-4d75-e6d5-f08e6a5501e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Extract month at index of DataFrame `df_time_based_events`, storing them as a new column 'EventMonth' in the DataFrame.\n",
        "@check_pandas_118\n",
        "def pandas_118(df_time_based_events):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_time_based_events['EventMonth'] = df_time_based_events['EventDate'].dt.month\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_time_based_events\": df_time_based_events}\n",
        "\n",
        "pandas_118()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzDjkaKkGD2j",
        "outputId": "ad75c465-9148-4cfb-f431-690ff7bb8887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Given a DataFrame `df_tennis_matches`, select rows using .loc where 'MatchesPlayed' > 20 and store them as `consistent_players`.\n",
        "@check_pandas_119\n",
        "def pandas_119(df_tennis_matches):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    consistent_players = df_tennis_matches.loc[df_tennis_matches['MatchesPlayed'] > 20]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"consistent_players\": consistent_players}\n",
        "\n",
        "pandas_119()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYFob8NmGD2j",
        "outputId": "868b4b88-cdc4-49c0-b5ef-17d87f15b23e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Utilize .iloc on DataFrame `df_daily_results` to select rows by integer location, focusing on every third row, and storing result as `every_third_result`.\n",
        "@check_pandas_120\n",
        "def pandas_120(df_daily_results):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    every_third_result = df_daily_results.iloc[::3]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"every_third_result\": every_third_result}\n",
        "\n",
        "pandas_120()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK5YzTomGD2k",
        "outputId": "f4a09272-52cf-4316-8bc2-dffb228f4a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# From DataFrame `df_survey_responses`, combine 'Question' and 'Answer' columns into a single 'Response' column, storing the result as a Series `consolidated_responses` in the format 'Question: Answer'.\n",
        "@check_pandas_121\n",
        "def pandas_121(df_survey_responses):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    consolidated_responses = df_survey_responses['Question'] + ': ' + df_survey_responses['Answer']\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"consolidated_responses\": consolidated_responses}\n",
        "\n",
        "pandas_121()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zouqc46kGD2k",
        "outputId": "f3462dbc-1476-4b64-b1f9-8d54b74242b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_server_logs` to group by 'ServerID' and calculate the sum and max of 'ResponseTime', storing result as `server_response_summary`.\n",
        "@check_pandas_122\n",
        "def pandas_122(df_server_logs):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    server_response_summary = df_server_logs.groupby('ServerID')['ResponseTime'].agg(['sum', 'max'])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"server_response_summary\": server_response_summary}\n",
        "\n",
        "pandas_122()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOhTrA80GD2k",
        "outputId": "2f755b7c-dd11-40ab-84cf-841acf7a327c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Modify DataFrame `df_machine_operating` by adding column 'Downtime' calculated from 'EndTime' minus 'StartTime', storing as `operations_with_downtime`.\n",
        "@check_pandas_123\n",
        "def pandas_123(df_machine_operating):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_machine_operating['StartTime'] = pd.to_datetime(df_machine_operating['StartTime'])\n",
        "    df_machine_operating['EndTime'] = pd.to_datetime(df_machine_operating['EndTime'])\n",
        "    df_machine_operating['Downtime'] = df_machine_operating['EndTime'] - df_machine_operating['StartTime']\n",
        "    operations_with_downtime = df_machine_operating\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"operations_with_downtime\": operations_with_downtime}\n",
        "\n",
        "pandas_123()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCXr27sYGD2k",
        "outputId": "bb3aecd5-4ed8-4062-b74b-83eb9947f09e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Remove duplicate rows from DataFrame `df_patient_visits`, considering only 'PatientID' and 'VisitDate', saving unique rows as `unique_patient_visits`.\n",
        "@check_pandas_124\n",
        "def pandas_124(df_patient_visits):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    unique_patient_visits = df_patient_visits.drop_duplicates(subset=['PatientID', 'VisitDate'])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"unique_patient_visits\": unique_patient_visits}\n",
        "\n",
        "pandas_124()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzSNvFRrGD2k",
        "outputId": "390f1234-2047-44ad-d417-025994bfc610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Optimize data processing speed in DataFrame `df_satellite_data` by converting all text-based columns to category type, storing efficient version as `satellite_optimized`.\n",
        "@check_pandas_125\n",
        "def pandas_125(df_satellite_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    satellite_optimized = df_satellite_data.copy()\n",
        "    satellite_optimized[satellite_optimized.select_dtypes(['object']).columns] = satellite_optimized.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"satellite_optimized\": satellite_optimized}\n",
        "\n",
        "pandas_125()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtPVxMQKGD2k",
        "outputId": "860af727-4392-4d9d-e9d8-03898951de99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use vectorized operations on DataFrame `df_temperature_logs` to convert 'TemperatureC' to Fahrenheit, storing the result in `temperature_fahrenheit`.\n",
        "@check_pandas_126\n",
        "def pandas_126(df_temperature_logs):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    temperature_fahrenheit = df_temperature_logs['TemperatureC'] * 9/5 + 32\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"temperature_fahrenheit\": temperature_fahrenheit}\n",
        "\n",
        "pandas_126()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIVxnWO4GD2k",
        "outputId": "55367ff9-c0ee-41e8-f319-2107aea09ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Group DataFrame `df_streaming_data` by 'UserID' and apply a lambda function to compute total view time, storing the result as `total_view_time`.\n",
        "@check_pandas_127\n",
        "def pandas_127(df_streaming_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    total_view_time = df_streaming_data.groupby('UserID')['ViewTime'].apply(lambda x: x.sum())\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"total_view_time\": total_view_time}\n",
        "\n",
        "pandas_127()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfgoysmBGD2k",
        "outputId": "654c0356-f3c5-4ff5-856c-9246c0fa3d65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_sales_analytics` to implement cohort analysis, calculating first purchase date and cohort index, storing result in `sales_cohorts`.\n",
        "@check_pandas_128\n",
        "def pandas_128(df_sales_analytics):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def get_cohort_index(df, column, first_purchase):\n",
        "        return (df[column].dt.year - first_purchase.dt.year) * 12 + (df[column].dt.month - first_purchase.dt.month) + 1\n",
        "\n",
        "    df_sales_analytics['PurchaseDate'] = pd.to_datetime(df_sales_analytics['PurchaseDate'])\n",
        "    df_sales_analytics['FirstPurchaseDate'] = df_sales_analytics.groupby('UserID')['PurchaseDate'].transform('min')\n",
        "    df_sales_analytics['CohortIndex'] = get_cohort_index(df_sales_analytics, 'PurchaseDate', df_sales_analytics['FirstPurchaseDate'])\n",
        "    sales_cohorts = df_sales_analytics[['UserID', 'PurchaseDate', 'FirstPurchaseDate', 'CohortIndex']]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sales_cohorts\": sales_cohorts}\n",
        "\n",
        "pandas_128()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYLtZXriGD2k",
        "outputId": "1fd2e841-1a8c-4998-bff4-cc0d47e8b05e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# In DataFrame `df_web_traffic`, apply conversion to 'Date' column from string to datetime, saving the updated DataFrame as `web_traffic_dates`.\n",
        "@check_pandas_129\n",
        "def pandas_129(df_web_traffic):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    web_traffic_dates = df_web_traffic.copy()\n",
        "    web_traffic_dates['Date'] = pd.to_datetime(web_traffic_dates['Date'])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"web_traffic_dates\": web_traffic_dates}\n",
        "\n",
        "pandas_129()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QjQOrd_GD2l",
        "outputId": "c32c3468-ad9f-4b05-b78a-60f69f01b84d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame `df_energy_savings` with datetime index representing bi-weekly dates over one year, filled with repetitive 5% and 10% energy savings, stored in 'SavingsPercent'.\n",
        "@check_pandas_130\n",
        "def pandas_130():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    date_range = pd.date_range(start='2024-01-01', end='2024-12-31', freq='2W')\n",
        "    savings_values = [5, 10] * (len(date_range) // 2)\n",
        "    df_energy_savings = pd.DataFrame({'SavingsPercent': savings_values}, index=date_range)\n",
        "    # ABOVE GOES YOUR CODE\\\n",
        "    return {\"df_energy_savings\": df_energy_savings}\n",
        "\n",
        "pandas_130()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5oiPirUGD2l",
        "outputId": "f96e2ba7-9031-4f4f-c40a-d46de73427b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# With DataFrame `df_vehicle_data`, apply method chaining to filter 'Type' as 'SUV' and sort by 'RecallDate', saving sorted SUVs as `sorted_suvs`.\n",
        "@check_pandas_131\n",
        "def pandas_131(df_vehicle_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    sorted_suvs = df_vehicle_data[df_vehicle_data['Type'] == 'SUV'].sort_values('RecallDate')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sorted_suvs\": sorted_suvs}\n",
        "\n",
        "pandas_131()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHZQY5WgGD2l",
        "outputId": "d532b893-0d9a-4e0d-b67f-32a207540a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Extract 'year' from 'DateAdmitted' in DataFrame `df_patient_admissions` using datetime operations, storing extracted years in `admission_years`.\n",
        "@check_pandas_132\n",
        "def pandas_132(df_patient_admissions):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_patient_admissions['DateAdmitted'] = pd.to_datetime(df_patient_admissions['DateAdmitted'])\n",
        "    admission_years = df_patient_admissions['DateAdmitted'].dt.year\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"admission_years\": admission_years}\n",
        "\n",
        "pandas_132()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXw1mkT1GD2l",
        "outputId": "03fe1cf8-0f57-49a6-958e-74b3e100f7ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Process DataFrame `df_cost_analysis` by converting 'Amount' to USD using 'Currency' which contains the type like ['EUR', 'GBP'] conversion rates being EUR: 1.12 and GBP: 1.30, storing result as `cost_analysis_usd` with column 'Amount' in 'Currency' and 'AmountUSD' in USD.\n",
        "@check_pandas_133\n",
        "def pandas_133(df_cost_analysis):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    conversion_rates = {'EUR': 1.12, 'GBP': 1.30}\n",
        "    df_cost_analysis['AmountUSD'] = df_cost_analysis.apply(\n",
        "        lambda row: row['Amount'] * conversion_rates.get(row['Currency'], 1),\n",
        "        axis=1\n",
        "    )\n",
        "    cost_analysis_usd = df_cost_analysis\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"cost_analysis_usd\": cost_analysis_usd}\n",
        "\n",
        "pandas_133()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNdoJfdNGD2l",
        "outputId": "7a308fae-f86f-484d-b28e-fa942008852e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# In DataFrame `df_logistics_data`, use rolling window of 30 days to calculate moving average inventory level, storing as `thirty_day_moving_inventory`.\n",
        "@check_pandas_134\n",
        "def pandas_134(df_logistics_data):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    thirty_day_moving_inventory = df_logistics_data['InventoryLevel'].rolling(window=30).mean()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"thirty_day_moving_inventory\": thirty_day_moving_inventory}\n",
        "\n",
        "pandas_134()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1XSsnZrGD2l",
        "outputId": "95406448-b401-4101-ae57-d409d1e7b19a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# From DataFrame `df_sports_results`, extract top three teams based on 'Scores', sorting first, saving top teams as `top_teams`.\n",
        "@check_pandas_135\n",
        "def pandas_135(df_sports_results):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    top_teams = df_sports_results.sort_values('Scores', ascending=False).head(3)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"top_teams\": top_teams}\n",
        "\n",
        "pandas_135()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wC7qQVBGD2l",
        "outputId": "d4175536-647e-48d8-fce0-6155520c4fbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_network_activity` statistics to calculate z-scores for 'Bandwidth', storing in column 'ZscoreBandwidth' as `network_with_zscore`.\n",
        "@check_pandas_136\n",
        "def pandas_136(df_network_activity):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_network_activity['ZscoreBandwidth'] = (df_network_activity['Bandwidth'] - df_network_activity['Bandwidth'].mean()) / df_network_activity['Bandwidth'].std()\n",
        "    network_with_zscore = df_network_activity\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"network_with_zscore\": network_with_zscore}\n",
        "\n",
        "pandas_136()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aH3q_H7GD2l",
        "outputId": "1e868e68-2fef-4720-cafe-ef2ccfe1aff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Perform inplace boolean update of `df_market_responses` setting all 'ResponseTime' > 300 to 300, saving updated DataFrame.\n",
        "@check_pandas_137\n",
        "def pandas_137(df_market_responses):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_market_responses.loc[df_market_responses['ResponseTime'] > 300, 'ResponseTime'] = 300\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_market_responses\": df_market_responses}\n",
        "\n",
        "pandas_137()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd0SjxrBGD2l",
        "outputId": "95a09e4c-e97d-40fd-b813-5fc236c6fbba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Analyze DataFrame `df_social_behaviors` applying transform with a custom function to 'EngagementRate' to normalize within each 'Group' by z-score, storing as 'NormalizedEngagementRate'.\n",
        "@check_pandas_138\n",
        "def pandas_138(df_social_behaviors):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def z_score_normalization(x):\n",
        "        return (x - x.mean()) / x.std()\n",
        "\n",
        "    df_social_behaviors['NormalizedEngagementRate'] = df_social_behaviors.groupby('Group')['EngagementRate'].transform(z_score_normalization)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"df_social_behaviors\": df_social_behaviors}\n",
        "\n",
        "pandas_138()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYFjDy9YGD2m",
        "outputId": "3aa721bd-21a4-43cf-f6e2-ef2d53520e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Use DataFrame `df_product_launch` to derive 'ResponseRate' from 'Inquiries' divided by 'Sales', multiplied by 100, storing as `launch_responses`.\n",
        "@check_pandas_139\n",
        "def pandas_139(df_product_launch):\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    df_product_launch['ResponseRate'] = (df_product_launch['Inquiries'] / df_product_launch['Sales']) * 100\n",
        "    launch_responses = df_product_launch\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"launch_responses\": launch_responses}\n",
        "\n",
        "pandas_139()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nXqd8nWGD2m",
        "outputId": "df026f28-fa9a-486f-9a5a-a0ca6548a10a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `create_series_from_dict` that takes a dictionary `input_dict` as an argument, and returns a pandas Series with the dictionary keys as the Series index.\n",
        "@check_pandas_140\n",
        "def pandas_3():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def create_series_from_dict(input_dict):\n",
        "        return pd.Series(input_dict)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"create_series_from_dict\": create_series_from_dict}\n",
        "\n",
        "pandas_3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qyy7dsnSGD2m",
        "outputId": "1e2558e3-aeb6-4052-f244-1b1597921c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `filter_series_positive` that takes a pandas Series `data_series` and returns a new Series containing only the elements where the value is positive.\n",
        "@check_pandas_141\n",
        "def pandas_4():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def filter_series_positive(data_series):\n",
        "        return data_series[data_series > 0]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"filter_series_positive\": filter_series_positive}\n",
        "\n",
        "pandas_4()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOprPriyGD2m",
        "outputId": "76cacc74-7282-4194-b150-92d715f327ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `rename_dataframe_columns` that accepts a DataFrame `df` and a dictionary `column_mapping`, and returns the DataFrame with renamed columns according to the mapping.\n",
        "@check_pandas_142\n",
        "def pandas_142():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def rename_dataframe_columns(df, column_mapping):\n",
        "        return df.rename(columns=column_mapping)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"rename_dataframe_columns\": rename_dataframe_columns}\n",
        "\n",
        "pandas_142()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zO9O9bkEGD2m",
        "outputId": "46e1dd1a-9118-40ab-a0e8-0537351632c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `drop_nan_rows` that takes a DataFrame `input_df` and returns a new DataFrame with all rows containing any NaN values removed.\n",
        "@check_pandas_143\n",
        "def pandas_143():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def drop_nan_rows(input_df):\n",
        "        return input_df.dropna()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"drop_nan_rows\": drop_nan_rows}\n",
        "\n",
        "pandas_143()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOTa7UMWGD2m",
        "outputId": "e9de49a7-6e26-42c6-830a-07199f292012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Construct a function `fill_missing_with_mean` which takes a DataFrame `df` and fills missing values in each numeric column with the mean of that column, returning the modified DataFrame.\n",
        "@check_pandas_144\n",
        "def pandas_144():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def fill_missing_with_mean(df):\n",
        "        return df.fillna(df.mean())\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"fill_missing_with_mean\": fill_missing_with_mean}\n",
        "\n",
        "pandas_144()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV924AofGD2m",
        "outputId": "900e7002-80cf-4178-9d63-285314eb3cbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `calculate_group_means` that takes a DataFrame `df` and a column name `group_col`, grouping by `group_col`, then returning the mean of each group as a Series.\n",
        "@check_pandas_145\n",
        "def pandas_145():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def calculate_group_means(df, group_col):\n",
        "        return df.groupby(group_col).mean()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_group_means\": calculate_group_means}\n",
        "\n",
        "pandas_145()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXYA7QwlGD2n",
        "outputId": "8d19b8e4-21d7-4c86-d81e-718799becf89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Design a function `subset_dataframe_label` that accepts a DataFrame `df`, a list `rows` of row labels, and returns a subset DataFrame containing only those rows.\n",
        "@check_pandas_146\n",
        "def pandas_146():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def subset_dataframe_label(df, rows):\n",
        "        return df.loc[rows]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"subset_dataframe_label\": subset_dataframe_label}\n",
        "\n",
        "pandas_146()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o6NDR0kGD2n",
        "outputId": "c9a9c6b5-6ce9-40f6-ba40-ac1ac2c17163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `merge_dataframes_on_key` that takes two DataFrames `df1`, `df2`, and a string `key`, merging them on the shared key column and returning the merged DataFrame.\n",
        "@check_pandas_147\n",
        "def pandas_147():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def merge_dataframes_on_key(df1, df2, key):\n",
        "        return pd.merge(df1, df2, on=key)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"merge_dataframes_on_key\": merge_dataframes_on_key}\n",
        "\n",
        "pandas_147()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOFnfIm1GD2n",
        "outputId": "f6c2c111-4553-4ce7-d305-8dcbd5fc8506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `aggregate_sales_by_region` which accepts a DataFrame `sales_df` that includes columns 'Region' and 'Sales', and returns a DataFrame with the total sales per region.\n",
        "@check_pandas_148\n",
        "def pandas_148():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def aggregate_sales_by_region(sales_df):\n",
        "        return sales_df.groupby('Region')['Sales'].sum().reset_index()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"aggregate_sales_by_region\": aggregate_sales_by_region}\n",
        "\n",
        "pandas_148()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDjG3ZL4GD2n",
        "outputId": "cf9c5c1b-6ad6-4d71-a8fd-ebf2cae88bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `pivot_table_for_analysis` that takes a DataFrame `df` and strings `index`, `columns`, `values`, and returns a pivot table using those specifications.\n",
        "@check_pandas_149\n",
        "def pandas_149():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def pivot_table_for_analysis(df, index, columns, values):\n",
        "        return pd.pivot_table(df, index=index, columns=columns, values=values)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"pivot_table_for_analysis\": pivot_table_for_analysis}\n",
        "\n",
        "pandas_149()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUQ0YxgiGD2n",
        "outputId": "00374de4-8f5f-47f9-f0a0-65a03a72db5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `calculate_rolling_average` that accepts a DataFrame `df` and an integer `window` to compute the rolling average of a numeric column `column_name`, returning the updated series.\n",
        "@check_pandas_150\n",
        "def pandas_150():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def calculate_rolling_average(df, column_name, window):\n",
        "        return df[column_name].rolling(window=window).mean()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_rolling_average\": calculate_rolling_average}\n",
        "\n",
        "pandas_150()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_xKpg71GD2n",
        "outputId": "6621ec7e-606c-4c38-f817-4f3275c30ed3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Construct a function `resample_time_series` which takes a time-indexed DataFrame `time_df` and a frequency string `freq`, resampling the DataFrame to the new frequency and summing, returning the result.\n",
        "@check_pandas_151\n",
        "def pandas_151():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def resample_time_series(time_df, freq):\n",
        "        return time_df.resample(freq).sum()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"resample_time_series\": resample_time_series}\n",
        "\n",
        "pandas_151()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGqcgywUGD2o",
        "outputId": "d2dff86c-5a8a-4f42-c9de-981fb5738220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `expand_string_columns` that takes a DataFrame `df` and a list of columns `string_columns`, expanding each string column to lowercase, and returns the modified DataFrame.\n",
        "@check_pandas_152\n",
        "def pandas_152():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def expand_string_columns(df, string_columns):\n",
        "        for col in string_columns:\n",
        "            df[col] = df[col].str.lower()\n",
        "        return df\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"expand_string_columns\": expand_string_columns}\n",
        "\n",
        "pandas_152()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUBIPXjZGD2o",
        "outputId": "323f85a2-4861-41b8-b219-0040433ba591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Design a function `convert_to_datetime_index` that accepts a DataFrame `df` and a column name `date_col`, converting it to a DateTimeIndex, and returning the updated DataFrame.\n",
        "@check_pandas_153\n",
        "def pandas_153():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def convert_to_datetime_index(df, date_col):\n",
        "        df[date_col] = pd.to_datetime(df[date_col])\n",
        "        df.set_index(date_col, inplace=True)\n",
        "        return df\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"convert_to_datetime_index\": convert_to_datetime_index}\n",
        "\n",
        "pandas_153()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXRDYLmHGD2o",
        "outputId": "acf06f2e-382d-45cf-ef42-99a52ed0daa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `identify_and_remove_outliers` that identifies outliers in a Series `data_series` using a specified `threshold` by removing the values outside of the `threshodl` multiplied by the standard deviation from the mean.\n",
        "@check_pandas_154\n",
        "def pandas_154():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def identify_and_remove_outliers(data_series, threshold):\n",
        "        mean = data_series.mean()\n",
        "        std = data_series.std()\n",
        "        lower_bound = mean - threshold * std\n",
        "        upper_bound = mean + threshold * std\n",
        "        return data_series[(data_series > lower_bound) & (data_series < upper_bound)]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"identify_and_remove_outliers\": identify_and_remove_outliers}\n",
        "\n",
        "pandas_154()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "164WRGq-GD2o",
        "outputId": "3d5e178a-b400-4955-cf71-8e95aa6cbe0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `calculate_percentage_change` which computes the percentage change over time for a Series `time_series` and returns the updated Series with NaN for the first entry.\n",
        "@check_pandas_155\n",
        "def pandas_155():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def calculate_percentage_change(time_series):\n",
        "        return time_series.pct_change()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_percentage_change\": calculate_percentage_change}\n",
        "\n",
        "pandas_155()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XwJXWRGGD2o",
        "outputId": "483bbcb2-baed-48c1-bb1e-27cb0345b2cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `categorize_based_on_values` which takes a DataFrame `df`, a column `categorical_col`, and returns a DataFrame with additional column 'Category' based on ranges in `categorical_col` with labels ['Low', 'Medium', 'High'] and bins [0, 100, 200, 300].\n",
        "@check_pandas_156\n",
        "def pandas_156():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def categorize_based_on_values(df, categorical_col):\n",
        "        df['Category'] = pd.cut(df[categorical_col], bins=[0, 100, 200, 300], labels=['Low', 'Medium', 'High'])\n",
        "        return df\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"categorize_based_on_values\": categorize_based_on_values}\n",
        "\n",
        "pandas_156()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT_bRKDIGD2o",
        "outputId": "d9b44fe6-4eec-4232-8abd-10a916c4b0fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `shift_dataframe_rows` that takes a DataFrame `df` and an integer `periods`, shifting all rows by the specified number of periods and returning the DataFrame.\n",
        "@check_pandas_157\n",
        "def pandas_157():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def shift_dataframe_rows(df, periods):\n",
        "        return df.shift(periods)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"shift_dataframe_rows\": shift_dataframe_rows}\n",
        "\n",
        "pandas_157()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRjR4IzmGD2p",
        "outputId": "a7626045-4e34-49f0-ae70-1c75f828c59f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `aggregate_and_flatten_grouped` that takes a grouped DataFrame `group_df` and returns a flattened DataFrame with 'sum' and 'count' aggregation for each group and reseted index.\n",
        "@check_pandas_158\n",
        "def pandas_158():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def aggregate_and_flatten_grouped(group_df):\n",
        "        return group_df.agg(['sum', 'count']).reset_index()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"aggregate_and_flatten_grouped\": aggregate_and_flatten_grouped}\n",
        "\n",
        "pandas_158()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsfwMaxaGD2p",
        "outputId": "11ff5e08-5fc2-45c6-c314-c5f6d801a75f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Construct a function named `remove_duplicates_by_columns` that takes a DataFrame `df` and a list `subset_columns`, and removes duplicate rows based on these columns, returning the resulting DataFrame.\n",
        "@check_pandas_159\n",
        "def pandas_159():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def remove_duplicates_by_columns(df, subset_columns):\n",
        "        return df.drop_duplicates(subset=subset_columns)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"remove_duplicates_by_columns\": remove_duplicates_by_columns}\n",
        "\n",
        "pandas_159()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zio3PA7GD2p",
        "outputId": "b6577ff7-5913-4521-fe4b-92daf8ebea67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Design a function `calculate_memory_usage` that takes a DataFrame `df` and returns the total memory usage in MB, both with and without optimizations for all columns possible.\n",
        "@check_pandas_160\n",
        "def pandas_160():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def calculate_memory_usage(df):\n",
        "        original_memory = df.memory_usage(deep=True).sum() / 1024 ** 2\n",
        "\n",
        "        optimized_df = df.copy()\n",
        "        for col in optimized_df.select_dtypes(include=['object']).columns:\n",
        "            optimized_df[col] = optimized_df[col].astype('category')\n",
        "\n",
        "        optimized_memory = optimized_df.memory_usage(deep=True).sum() / 1024 ** 2\n",
        "        return original_memory, optimized_memory\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_memory_usage\": calculate_memory_usage}\n",
        "\n",
        "pandas_160()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfN-t-EHGD2p",
        "outputId": "22879374-6469-4a81-b746-e3c00c5c42db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `map_values_with_dict` which accepts a DataFrame `df`, a column `target_col`, and a dictionary `value_map`, returning the updated DataFrame after mapping.\n",
        "@check_pandas_161\n",
        "def pandas_161():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def map_values_with_dict(df, target_col, value_map):\n",
        "        df[target_col] = df[target_col].map(value_map)\n",
        "        return df\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"map_values_with_dict\": map_values_with_dict}\n",
        "\n",
        "pandas_161()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ify7O3S5GD2p",
        "outputId": "1705d036-a9d8-4100-9aaf-723842b327ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `select_top_n_rows_based_on_column` that takes a DataFrame `df`, a column `target_col`, and an integer `n`, and returns the top `n` rows sorted by `target_col`.\n",
        "@check_pandas_162\n",
        "def pandas_162():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def select_top_n_rows_based_on_column(df, target_col, n):\n",
        "        return df.nlargest(n, target_col)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"select_top_n_rows_based_on_column\": select_top_n_rows_based_on_column}\n",
        "\n",
        "pandas_162()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHUZiHW4GD2p",
        "outputId": "8435e09c-0f3e-45c4-f0d0-1e5c2295c1ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `replace_substrings_in_column` that takes a DataFrame `df`, a column `text_col`, a string `old`, and a string `new`, replacing all occurrences of `old` with `new` in `text_col`.\n",
        "@check_pandas_163\n",
        "def pandas_163():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def replace_substrings_in_column(df, text_col, old, new):\n",
        "        df[text_col] = df[text_col].str.replace(old, new)\n",
        "        return df\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"replace_substrings_in_column\": replace_substrings_in_column}\n",
        "\n",
        "pandas_163()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncZPi7mYGD2q",
        "outputId": "9d252978-d63b-4836-c122-0e83a1548d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `apply_discretization_binner` which bins Series `data_series` into a specified number of discrete intervals `n_bins` and returns the binned Series.\n",
        "@check_pandas_164\n",
        "def pandas_164():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def apply_discretization_binner(data_series, n_bins):\n",
        "        return pd.cut(data_series, bins=n_bins)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"apply_discretization_binner\": apply_discretization_binner}\n",
        "\n",
        "pandas_164()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfpeDJafGD2q",
        "outputId": "b2a24921-aaf0-46d3-d6c2-97f217fbe105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `generate_descriptive_statistics` that takes a DataFrame `df` and returns a DataFrame with descriptive statistics such as mean, median, and standard deviation for all numeric columns.\n",
        "@check_pandas_165\n",
        "def pandas_165():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def generate_descriptive_statistics(df):\n",
        "        return df.describe()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"generate_descriptive_statistics\": generate_descriptive_statistics}\n",
        "\n",
        "pandas_165()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8IHW3vmGD2q",
        "outputId": "ba6c7e89-1f9a-42ac-eb68-e1f01384d7e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `convert_column_dtype` that accepts a DataFrame `df`, a column name `col`, and a data type `new_type`, and returns the DataFrame with `col` converted to `new_type`.\n",
        "@check_pandas_166\n",
        "def pandas_166():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def convert_column_dtype(df, col, new_type):\n",
        "        df[col] = df[col].astype(new_type)\n",
        "        return df\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"convert_column_dtype\": convert_column_dtype}\n",
        "\n",
        "pandas_166()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0-FqVyxGD2q",
        "outputId": "051fa46d-ca0c-42a0-b39b-161886db4e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `sort_dataframe_by_multiple_columns` taking DataFrame `df` and a list `columns_list` to sort the DataFrame by these columns, returning the sorted DataFrame.\n",
        "@check_pandas_167\n",
        "def pandas_167():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def sort_dataframe_by_multiple_columns(df, columns_list):\n",
        "        return df.sort_values(columns_list)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sort_dataframe_by_multiple_columns\": sort_dataframe_by_multiple_columns}\n",
        "\n",
        "pandas_167()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYg5q8A7GD2q",
        "outputId": "7804c13d-48dd-4eef-9eda-125374f010e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `create_time_based_features` which accepts a DataFrame `time_df` with a 'Timestamp' column and returns the DataFrame with new columns for hour, day, and month.\n",
        "@check_pandas_168\n",
        "def pandas_168():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def create_time_based_features(time_df):\n",
        "        time_df['Timestamp'] = pd.to_datetime(time_df['Timestamp'])\n",
        "        time_df['Hour'] = time_df['Timestamp'].dt.hour\n",
        "        time_df['Day'] = time_df['Timestamp'].dt.day\n",
        "        time_df['Month'] = time_df['Timestamp'].dt.month\n",
        "        return time_df\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"create_time_based_features\": create_time_based_features}\n",
        "\n",
        "pandas_168()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXZvq--7GD2q",
        "outputId": "8a871f2a-606b-46a8-a735-194a24d7029f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `analyze_sales_data` that takes a DataFrame `sales_df` with columns 'Date', 'Region', and 'Sales'. The function should: Convert 'Date' to a DateTime object; Filter out any rows where 'Sales' is negative; Group by 'Region' to calculate the total and average sales; Return a DataFrame with columns 'Region', 'TotalSales', 'AverageSales';\n",
        "@check_pandas_169\n",
        "def pandas_169():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def analyze_sales_data(sales_df):\n",
        "        sales_df['Date'] = pd.to_datetime(sales_df['Date'])\n",
        "        sales_df = sales_df[sales_df['Sales'] >= 0]\n",
        "        sales_summary = sales_df.groupby('Region')['Sales'].agg(['sum', 'mean']).reset_index()\n",
        "        sales_summary.columns = ['Region', 'TotalSales', 'AverageSales']\n",
        "        return sales_summary\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"analyze_sales_data\": analyze_sales_data}\n",
        "\n",
        "pandas_169()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41Ew5W43GD2r",
        "outputId": "7449a271-f776-45a5-d362-9d74152d6354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `clean_and_merge_datasets` that takes two DataFrames `df_left` and `df_right`, and: Fills NA values in `df_left` with 0; Drops any duplicate rows in `df_right`; Merges the cleaned DataFrames on a common column 'Key', using an outer join; Returns the merged DataFrame sorted by 'Key';\n",
        "@check_pandas_170\n",
        "def pandas_170():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def clean_and_merge_datasets(df_left, df_right):\n",
        "        df_left.fillna(0, inplace=True)\n",
        "        df_right.drop_duplicates(inplace=True)\n",
        "        merged_df = pd.merge(df_left, df_right, on='Key', how='outer')\n",
        "        return merged_df.sort_values('Key')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"clean_and_merge_datasets\": clean_and_merge_datasets}\n",
        "\n",
        "pandas_170()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge-fSszNGD2r",
        "outputId": "cc2f73ee-01ef-4d48-f5f8-275caed3a2f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `process_sensor_data_batch` that receives a DataFrame `sensor_df` containing 'SensorID', 'ReadingValue', 'Timestamp'. Convert 'Timestamp' to datetime format; Ensure all 'ReadingValue' entries are non-negative; Calculate the mean and standard deviation of 'ReadingValue' for each 'SensorID'; Return a DataFrame with 'SensorID', 'MeanReading', 'StdDevReading';\n",
        "@check_pandas_171\n",
        "def pandas_171():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def process_sensor_data_batch(sensor_df):\n",
        "        sensor_df['Timestamp'] = pd.to_datetime(sensor_df['Timestamp'])\n",
        "        sensor_df = sensor_df[sensor_df['ReadingValue'] >= 0]\n",
        "        sensor_summary = sensor_df.groupby('SensorID')['ReadingValue'].agg(['mean', 'std']).reset_index()\n",
        "        sensor_summary.columns = ['SensorID', 'MeanReading', 'StdDevReading']\n",
        "        return sensor_summary\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"process_sensor_data_batch\": process_sensor_data_batch}\n",
        "\n",
        "pandas_171()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXwU9QuyGD2r",
        "outputId": "c93792c2-5cd9-482e-cfbf-6d9b3d9e577c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Construct a function `analyze_customer_behaviors` to handle a DataFrame `customer_df` with columns 'CustomerID', 'PurchaseAmount', 'VisitTimestamp'. Convert 'VisitTimestamp' to a DateTimeIndex; Filter to include only purchases greater than a specified `min_purchase`; Group by 'CustomerID' to determine the total and count of purchases; Return a DataFrame with 'CustomerID', 'TotalPurchases', 'NumberVisits', and attach the most recent visit date;\n",
        "@check_pandas_172\n",
        "def pandas_172():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def analyze_customer_behaviors(customer_df, min_purchase):\n",
        "        customer_df['VisitTimestamp'] = pd.to_datetime(customer_df['VisitTimestamp'])\n",
        "        customer_df = customer_df[customer_df['PurchaseAmount'] > min_purchase]\n",
        "        customer_summary = customer_df.groupby('CustomerID').agg(\n",
        "            TotalPurchases=('PurchaseAmount', 'sum'),\n",
        "            NumberVisits=('PurchaseAmount', 'count'),\n",
        "            MostRecentVisit=('VisitTimestamp', 'max')\n",
        "        ).reset_index()\n",
        "        return customer_summary\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"analyze_customer_behaviors\": analyze_customer_behaviors}\n",
        "\n",
        "pandas_172()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVebCvLQGD2r",
        "outputId": "1900b24f-3465-49b3-b6c1-4eb403661ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `transform_financial_data` that processes a DataFrame `financial_df` including columns 'AccountID', 'TransactionDate', 'Amount'. Parse 'TransactionDate' into datetime and set as index; Filter 'Amount' to exclude NaN and zero values; Extract month and year from 'TransactionDate' into new columns `Month`, `Year`; Group by 'AccountID' and 'Year' to summarize monthly 'Amount' into sum and mean, returning a structured DataFrame;\n",
        "@check_pandas_173\n",
        "def pandas_173():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def transform_financial_data(financial_df):\n",
        "        financial_df['TransactionDate'] = pd.to_datetime(financial_df['TransactionDate'])\n",
        "        financial_df = financial_df.set_index('TransactionDate')\n",
        "        financial_df = financial_df[financial_df['Amount'].notna() & (financial_df['Amount'] != 0)]\n",
        "        financial_df['Month'] = financial_df.index.month\n",
        "        financial_df['Year'] = financial_df.index.year\n",
        "        grouped_df = financial_df.groupby(['AccountID', 'Year', 'Month'])['Amount'].agg(['sum', 'mean']).reset_index()\n",
        "        return grouped_df\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"transform_financial_data\": transform_financial_data}\n",
        "\n",
        "pandas_173()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHYnePqBGD2r",
        "outputId": "6695d955-d302-42b2-bf3c-ed590711c2f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `aggregate_weather_data` for a DataFrame `weather_df` with fields 'StationID', 'Temp', 'Humidity', 'ObservationTime'. Convert 'ObservationTime' to a DateTimeIndex; Filter to retain records with positive 'Temp' and 'Humidity'; Resample to daily frequency, taking the mean for each day; Return a DataFrame grouped by 'StationID' with columns for daily average 'Temp' and 'Humidity';\n",
        "@check_pandas_174\n",
        "def pandas_174():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def aggregate_weather_data(weather_df):\n",
        "        weather_df['ObservationTime'] = pd.to_datetime(weather_df['ObservationTime'])\n",
        "        weather_df = weather_df.set_index('ObservationTime')\n",
        "        weather_df = weather_df[(weather_df['Temp'] > 0) & (weather_df['Humidity'] > 0)]\n",
        "        daily_df = weather_df.resample('D').mean()\n",
        "        grouped_df = daily_df.groupby('StationID')[['Temp', 'Humidity']].mean().reset_index()\n",
        "        return grouped_df\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"aggregate_weather_data\": aggregate_weather_data}\n",
        "\n",
        "pandas_174()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqsjjiNrGD2s",
        "outputId": "7b745737-6db8-491f-e841-d2094e22b53b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Design a function `standardize_student_record` to clean a DataFrame `student_df` featuring 'Name', 'Score', 'SubmissionDate'. Standardize 'Name' to have a capitalized first letter; Address missing 'Score' values by assigning the median score; Standardize 'SubmissionDate' to a consistent format and compute 'DaysSinceSubmission'; Return a DataFrame with standardized names, computed days since submission, and filled scores;\n",
        "@check_pandas_175\n",
        "def pandas_175():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def standardize_student_record(student_df):\n",
        "        student_df['Name'] = student_df['Name'].str.capitalize()\n",
        "        student_df['Score'] = student_df['Score'].fillna(student_df['Score'].median())\n",
        "        student_df['SubmissionDate'] = pd.to_datetime(student_df['SubmissionDate'])\n",
        "        student_df['DaysSinceSubmission'] = (pd.Timestamp.now() - student_df['SubmissionDate']).dt.days\n",
        "        return student_df\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"standardize_student_record\": standardize_student_record}\n",
        "\n",
        "pandas_175()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dcd3pIXGD2s",
        "outputId": "9d20edf7-a975-4b25-9f4b-f4885627de62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `construct_inventory_report` that takes a DataFrame `inventory_df` with 'ItemID', 'Quantity', 'RestockDate'. Parse 'RestockDate' to ensure it's in datetime format; Identify items needing restock by checking 'Quantity' against the `threshold`; Provide a summary count of items needing restock by month; Return a detailed DataFrame with 'ItemID', 'Quantity', 'DaysUntilRestock', plus a monthly summary DataFrame;\n",
        "@check_pandas_176\n",
        "def pandas_176():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def construct_inventory_report(inventory_df, threshold):\n",
        "        inventory_df['RestockDate'] = pd.to_datetime(inventory_df['RestockDate'])\n",
        "        inventory_df['DaysUntilRestock'] = (inventory_df['RestockDate'] - pd.Timestamp.now()).dt.days\n",
        "        restock_df = inventory_df[inventory_df['Quantity'] < threshold]\n",
        "        restock_df['Month'] = restock_df['RestockDate'].dt.to_period('M')\n",
        "        monthly_summary = restock_df.groupby('Month')['ItemID'].count().reset_index()\n",
        "        return restock_df[['ItemID', 'Quantity', 'DaysUntilRestock']], monthly_summary\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"construct_inventory_report\": construct_inventory_report}\n",
        "\n",
        "pandas_176()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr-0h5HhGD2s",
        "outputId": "4881c119-a98d-4a49-c4ff-1b977c67cb16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `optimize_sales_forecast` that works on DataFrame `forecast_df` with columns 'Product', 'ProjectedSales', 'ForecastDate'. Convert 'ForecastDate' to DateTime format; Apply forward fill to handle missing 'ProjectedSales' values; Conduct a rolling window analysis to compute the 3-month moving average of sales; Return an extended DataFrame with moving averages along with original columns;\n",
        "@check_pandas_177\n",
        "def pandas_177():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def optimize_sales_forecast(forecast_df):\n",
        "        forecast_df['ForecastDate'] = pd.to_datetime(forecast_df['ForecastDate'])\n",
        "        forecast_df['ProjectedSales'] = forecast_df['ProjectedSales'].ffill()\n",
        "        forecast_df['MovingAverage'] = forecast_df['ProjectedSales'].rolling(window=3).mean()\n",
        "        return forecast\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"optimize_sales_forecast\": optimize_sales_forecast}\n",
        "\n",
        "pandas_177()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUYtzSqdGD2s",
        "outputId": "aaff6959-babd-43df-976b-b1eff75506e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `summarize_employee_performance` that processes DataFrame `performance_df` with 'EmployeeID', 'Score', 'ReviewDate'. Ensure 'ReviewDate' is converted into a datetime object; Replace missing 'Score' with the lowest non-zero score; Group by 'EmployeeID' to compute total and average score; Generate a DataFrame highlighting top performers with scores above a specified percentile score; Audit history, including evaluation of performance improvement over time;\n",
        "@check_pandas_178\n",
        "def pandas_178():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def summarize_employee_performance(performance_df, percentile_score):\n",
        "        performance_df['ReviewDate'] = pd.to_datetime(performance_df['ReviewDate'])\n",
        "        performance_df['Score'] = performance_df['Score'].replace(0, np.nan).fillna(performance_df['Score'].min())\n",
        "        performance_summary = performance_df.groupby('EmployeeID')['Score'].agg(['sum', 'mean']).reset_index()\n",
        "        top_performers = performance_summary[performance_summary['mean'] > np.percentile(performance_summary['mean'], percentile_score)]\n",
        "        return performance_summary, top_performers\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"summarize_employee_performance\": summarize_employee_performance}\n",
        "\n",
        "pandas_178()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5BusuX1GD2s",
        "outputId": "aec156e6-e68e-4cd2-961b-c6f56d613155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `double_series_values` that takes a Series `input_series` and returns a Series with all values doubled.\n",
        "@check_pandas_179\n",
        "def pandas_179():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def double_series_values(input_series):\n",
        "        return input_series * 2\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"double_series_values\": double_series_values}\n",
        "\n",
        "pandas_179()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWXg_4uiGD2t",
        "outputId": "2e115a92-26ab-4b6f-da70-a66ed6c55f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `replace_zeros_with_mean` that takes a Series `data_series` and replaces all 0 values with the mean of the Series, returning the modified Series.\n",
        "@check_pandas_180\n",
        "def pandas_180():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def replace_zeros_with_mean(data_series):\n",
        "        data_series[data_series == 0] = data_series[data_series != 0].mean()\n",
        "        return data_series\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"replace_zeros_with_mean\": replace_zeros_with_mean}\n",
        "\n",
        "pandas_180()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inVknAAXGD2t",
        "outputId": "35077d7c-b6ab-458f-c7d1-f11359eb549e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Design a function `standardize_column_names` that accepts a DataFrame `df` and returns it with all column names set to lowercase.\n",
        "@check_pandas_181\n",
        "def pandas_181():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def standardize_column_names(df):\n",
        "        return df.rename(columns=str.lower)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"standardize_column_names\": standardize_column_names}\n",
        "\n",
        "pandas_181()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwJfqecfGD2t",
        "outputId": "f55aeef3-1512-42d5-ad5e-0abba8f2418a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `drop_duplicate_rows` that receives a DataFrame `df` and returns it with duplicate rows removed.\n",
        "@check_pandas_182\n",
        "def pandas_182():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def drop_duplicate_rows(df):\n",
        "        return df.drop_duplicates()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"drop_duplicate_rows\": drop_duplicate_rows}\n",
        "\n",
        "pandas_182()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mG7d-HDNGD2t",
        "outputId": "b38eee96-8cff-4525-c977-56abefb784f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `calculate_column_sums` that takes a DataFrame `df` and returns a Series containing the sum of each column.\n",
        "@check_pandas_183\n",
        "def pandas_183():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def calculate_column_sums(df):\n",
        "        return df.sum()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_column_sums\": calculate_column_sums}\n",
        "\n",
        "pandas_183()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEePKP5oGD2t",
        "outputId": "a9f3df32-d879-42e4-efc7-ca938675a59a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `extract_date_parts` that takes a Series `dates` of datetime objects and returns a DataFrame with columns 'Year', 'Month', and 'Day'.\n",
        "@check_pandas_184\n",
        "def pandas_184():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def extract_date_parts(dates):\n",
        "        return pd.DataFrame({\n",
        "            'Year': dates.dt.year,\n",
        "            'Month': dates.dt.month,\n",
        "            'Day': dates.dt.day\n",
        "        })\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"extract_date_parts\": extract_date_parts}\n",
        "\n",
        "pandas_184()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJcg_5X7GD2t",
        "outputId": "feea30ad-3049-4042-9407-36ecb03c5d29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `concat_strings_in_column` that, given a DataFrame `df` and a column `text_col`, concatenates all strings in that column with a space in between, returning the result string.\n",
        "@check_pandas_185\n",
        "def pandas_185():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def concat_strings_in_column(df, text_col):\n",
        "        return ' '.join(df[text_col])\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"concat_strings_in_column\": concat_strings_in_column}\n",
        "\n",
        "pandas_185()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Inystd2LGD2u",
        "outputId": "83cd7a3c-f2dc-43a9-b4ff-6f716beb8516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `sort_by_index_descending` that accepts a DataFrame `df` and returns it sorted by its index in descending order.\n",
        "@check_pandas_186\n",
        "def pandas_186():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def sort_by_index_descending(df):\n",
        "        return df.sort_index(ascending=False)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sort_by_index_descending\": sort_by_index_descending}\n",
        "\n",
        "pandas_186()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bu_s4y5GD2u",
        "outputId": "722dbbd5-856d-44b6-8243-6dba0f6146b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `filter_by_threshold` to take a DataFrame `df` and a column name `col`, returning a DataFrame including only rows where `col` is above a given threshold.\n",
        "@check_pandas_187\n",
        "def pandas_187():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def filter_by_threshold(df, col, threshold):\n",
        "        return df[df[col] > threshold]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"filter_by_threshold\": filter_by_threshold}\n",
        "\n",
        "pandas_187()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxxmyaGLGD2u",
        "outputId": "8bd597cb-e8cc-47fb-eafc-9f5dd2bc54f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `get_unique_values` that takes a DataFrame `df` and a column `col`, returning a sorted array of unique values in the specified column.\n",
        "@check_pandas_188\n",
        "def pandas_188():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def get_unique_values(df, col):\n",
        "        return df[col].unique()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"get_unique_values\": get_unique_values}\n",
        "\n",
        "pandas_188()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldwxexZyGD2u",
        "outputId": "5025104e-856c-48af-d006-7691eb17470e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `append_row_to_dataframe` that takes a DataFrame `df` and a dictionary `row_dict`, appending the dictionary as a new row, and returning the updated DataFrame.\n",
        "@check_pandas_189\n",
        "def pandas_189():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def append_row_to_dataframe(df, row_dict):\n",
        "        return df.append(row_dict, ignore_index=True)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"append_row_to_dataframe\": append_row_to_dataframe}\n",
        "\n",
        "pandas_189()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyr8rv11GD2u",
        "outputId": "2de25081-3681-4dd9-95b0-33c05efb91d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Construct a function `reset_index_and_name` that takes a DataFrame `df` and returns it with its index reset and the name of the index set to 'NewIndex'.\n",
        "@check_pandas_190\n",
        "def pandas_190():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def reset_index_and_name(df):\n",
        "        return df.reset_index().rename_axis('NewIndex')\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"reset_index_and_name\": reset_index_and_name}\n",
        "\n",
        "pandas_190()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz2DIAN8GD2u",
        "outputId": "abd3abb4-b15b-4c9f-9fc9-1602109528c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `swap_dataframe_columns` that accepts a DataFrame `df` and two column names `col1` and `col2`, swapping the values of these columns.\n",
        "@check_pandas_191\n",
        "def pandas_191():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def swap_dataframe_columns(df, col1, col2):\n",
        "        df[col1], df[col2] = df[col2], df[col1]\n",
        "        return df\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"swap_dataframe_columns\": swap_dataframe_columns}\n",
        "\n",
        "pandas_191()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "690baFPWGD2u",
        "outputId": "12c030fe-6e5a-4e41-d8a7-49f96fa0534d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `rename_index_label` which receives a DataFrame `df`, renames its first index label to 'FirstRow', and returns the DataFrame.\n",
        "@check_pandas_192\n",
        "def pandas_192():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def rename_index_label(df):\n",
        "        df.index = df.index.rename(['FirstRow'] + df.index.tolist()[1:])\n",
        "        return df\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"rename_index_label\": rename_index_label}\n",
        "\n",
        "pandas_192()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiQp5d6yGD2v",
        "outputId": "1cf94409-0b69-40c4-ee68-757b9ac1e5cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❗ The implementation is incorrect or the exercise was not implemented.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `calculate_frequency_table` that, given a DataFrame `df` and a column `cat_col`, returns a DataFrame with a frequency count of each category with columns Category and count.\n",
        "@check_pandas_193\n",
        "def pandas_193():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def calculate_frequency_table(df, cat_col):\n",
        "        return df[cat_col].value_counts().reset_index().rename(columns={cat_col: 'count', 'index': 'Category'})\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_frequency_table\": calculate_frequency_table}\n",
        "\n",
        "pandas_193()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jigy-XdcGD2v",
        "outputId": "f1050689-c89f-4679-d7e8-658a373eb9a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Implement a function `remove_negative_entries` that takes a Series `numeric_series` and returns a Series with all negative entries removed.\n",
        "@check_pandas_194\n",
        "def pandas_194():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def remove_negative_entries(numeric_series):\n",
        "        return numeric_series[numeric_series >= 0]\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"remove_negative_entries\": remove_negative_entries}\n",
        "\n",
        "pandas_194()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt405mlSGD2v",
        "outputId": "99c466c8-d1c0-4c19-dae4-1fd39192ffc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `sort_column_values` that takes a DataFrame `df` and column name `col`, returning `df` sorted by `col` values in ascending order.\n",
        "@check_pandas_195\n",
        "def pandas_195():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def sort_column_values(df, col):\n",
        "        return df.sort_values(col)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"sort_column_values\": sort_column_values}\n",
        "\n",
        "pandas_195()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct8yA8vmGD2v",
        "outputId": "53b2af79-ac09-4dac-e98d-b7dfbc16c93e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Design a function `drop_columns_by_name` that accepts a DataFrame `df` and a list of column names `drop_cols`, removing these columns and returning the modified DataFrame.\n",
        "@check_pandas_196\n",
        "def pandas_196():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def drop_columns_by_name(df, drop_cols):\n",
        "        return df.drop(columns=drop_cols)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"drop_columns_by_name\": drop_columns_by_name}\n",
        "\n",
        "pandas_196()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeXtfYWQGD2v",
        "outputId": "457db5be-89a5-4ea6-f796-a434b1742dce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_9392\\3557299837.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
            "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_9392\\3557299837.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
            "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_9392\\3557299837.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
          ]
        }
      ],
      "source": [
        "# Develop a function `strip_whitespace` that takes a DataFrame `df` and trims leading and trailing whitespace from all string entries.\n",
        "@check_pandas_197\n",
        "def pandas_197():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def strip_whitespace(df):\n",
        "        return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"strip_whitespace\": strip_whitespace}\n",
        "\n",
        "pandas_197()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUEwqpcSGD2v",
        "outputId": "56dea6f7-ce24-430a-98c8-bd428b0791a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a function `duplicate_last_column` that receives a DataFrame `df` and duplicates its last column, appending the duplicate to the right of the DataFrame named as the original column with '_copy' appended.\n",
        "@check_pandas_198\n",
        "def pandas_198():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def duplicate_last_column(df):\n",
        "        last_col = df.columns[-1]\n",
        "        df[last_col + '_copy'] = df[last_col]\n",
        "        return df\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"duplicate_last_column\": duplicate_last_column}\n",
        "\n",
        "pandas_198()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O50nAvhGD2w",
        "outputId": "5dd74fb1-b21d-40de-ce52-1869bc226621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Write a function `filter_top_n_rows_by_column` that takes a DataFrame `df`, a column `col`, and an integer `n`, returning the top n rows sorted by values in `col`.\n",
        "@check_pandas_199\n",
        "def pandas_199():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def filter_top_n_rows_by_column(df, col, n):\n",
        "        return df.nlargest(n, col)\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"filter_top_n_rows_by_column\": filter_top_n_rows_by_column}\n",
        "\n",
        "pandas_199()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH2GDSzWGD2w",
        "outputId": "0f82fc21-6f27-4782-e23d-972c0a4e70a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Great job! Exercise completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Define a function `calculate_range_of_numeric_series` that takes a Series `numeric_series` and returns the range (max - min) of its values.\n",
        "@check_pandas_200\n",
        "def pandas_200():\n",
        "    # This line is mandatory and should not be removed.\n",
        "    ex_stat_init = True\n",
        "\n",
        "    # BELOW GOES YOUR CODE\n",
        "    def calculate_range_of_numeric_series(numeric_series):\n",
        "        return numeric_series.max() - numeric_series.min()\n",
        "    # ABOVE GOES YOUR CODE\n",
        "    return {\"calculate_range_of_numeric_series\": calculate_range_of_numeric_series}\n",
        "\n",
        "pandas_200()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}